#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
ì¢…í•© ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„±
Comprehensive Summary Report
"""

import sys
if sys.platform.startswith("win") and hasattr(sys.stdout, "reconfigure"):
    sys.stdout.reconfigure(encoding='utf-8')

import pandas as pd
import numpy as np
from pathlib import Path

OUTPUT_DIR = Path("results/analysis_outputs")

print("=" * 80)
print("ì¢…í•© ë¶„ì„ ë¦¬í¬íŠ¸")
print("Comprehensive Summary Report")
print("=" * 80)

# =============================================================================
# Load all analysis results
# =============================================================================

# 1. Gender moderation
gender_simple_slopes = pd.read_csv(OUTPUT_DIR / "gender_simple_slopes.csv")
gender_permutation = pd.read_csv(OUTPUT_DIR / "gender_permutation_test.csv")
gender_bootstrap = pd.read_csv(OUTPUT_DIR / "gender_bootstrap_ci.csv")

# 2. Reliability correction
disattenuated = pd.read_csv(OUTPUT_DIR / "disattenuated_correlations.csv")
power_corrected = pd.read_csv(OUTPUT_DIR / "power_analysis_corrected.csv")

# 3. Latent profiles
lpa_anova = pd.read_csv(OUTPUT_DIR / "lpa_ef_anova.csv")
lpa_profiles = pd.read_csv(OUTPUT_DIR / "lpa_profile_means.csv")

# 4. Trial variability
iiv_corr = pd.read_csv(OUTPUT_DIR / "iiv_correlations.csv")
pes_corr = pd.read_csv(OUTPUT_DIR / "pes_correlations.csv")

# 5. Ultra-deep analysis
ultradeep_gender = pd.read_csv(OUTPUT_DIR / "ultradeep_gender_stratified.csv")
ultradeep_nonlinear = pd.read_csv(OUTPUT_DIR / "ultradeep_nonlinear_tests.csv")
ultradeep_robust = pd.read_csv(OUTPUT_DIR / "ultradeep_robust_regression.csv")

# 6. Original core results
corr_matrix = pd.read_csv(OUTPUT_DIR / "correlation_matrix.csv", index_col=0)
hierarchical = pd.read_csv(OUTPUT_DIR / "hierarchical_regression_results.csv")

# =============================================================================
# Create summary report
# =============================================================================

report = []

report.append("=" * 80)
report.append("ì™¸ë¡œì›€-ì§‘í–‰ê¸°ëŠ¥ ì—°êµ¬ ì¢…í•© ë¶„ì„ ë¦¬í¬íŠ¸")
report.append("Loneliness & Executive Function: Comprehensive Analysis Report")
report.append("=" * 80)
report.append("")

# PART 1: Overview
report.append("PART 1: ì—°êµ¬ ê°œìš”")
report.append("-" * 80)
report.append("ì—°êµ¬ ì§ˆë¬¸: UCLA ì™¸ë¡œì›€ì´ ì§‘í–‰ê¸°ëŠ¥(EF) ìˆ˜í–‰ì— ì˜í–¥ì„ ë¯¸ì¹˜ëŠ”ê°€?")
report.append("ì¸¡ì • ê³¼ì œ:")
report.append("  - Stroop ê³¼ì œ (ê°„ì„­íš¨ê³¼)")
report.append("  - WCST (ìœ„ìŠ¤ì½˜ì‹  ì¹´ë“œ ë¶„ë¥˜ ê²€ì‚¬ - ë³´ì†ì˜¤ë¥˜ìœ¨)")
report.append("  - PRP (ì‹¬ë¦¬ì  ë¶ˆì‘ê¸° - ë³‘ëª©íš¨ê³¼)")
report.append("ê³µë³€ì¸: DASS-21 (ìš°ìš¸, ë¶ˆì•ˆ, ìŠ¤íŠ¸ë ˆìŠ¤)")
report.append("ìƒ˜í”Œ: N=72 (ì—¬ì„± 45ëª…, ë‚¨ì„± 27ëª…)")
report.append("")

# PART 2: Main Effects
report.append("PART 2: ì£¼íš¨ê³¼ ë¶„ì„ ê²°ê³¼")
report.append("-" * 80)
report.append("")
report.append("2.1 Zero-order ìƒê´€ (UCLA â†” EF)")
report.append("")

for outcome in ['stroop_interference', 'perseverative_error_rate', 'prp_bottleneck']:
    outcome_label = {
        'stroop_interference': 'Stroop ê°„ì„­',
        'perseverative_error_rate': 'WCST ë³´ì†ì˜¤ë¥˜ìœ¨',
        'prp_bottleneck': 'PRP ë³‘ëª©íš¨ê³¼'
    }[outcome]

    r = corr_matrix.loc['ucla_total', outcome]
    report.append(f"  {outcome_label}: r = {r:.3f}")

report.append("")
report.append("â†’ ëª¨ë“  ìƒê´€ì´ ë§¤ìš° ì•½í•¨ (|r| < 0.10)")
report.append("")

report.append("2.2 ìœ„ê³„ì  íšŒê·€ (DASS í†µì œ í›„ UCLA íš¨ê³¼)")
report.append("")

for _, row in hierarchical.iterrows():
    outcome_label = row['outcome'].replace('_', ' ').title()
    delta_r2 = row['delta_r2']
    p = row['p_value']
    report.append(f"  {outcome_label}:")
    report.append(f"    Î”RÂ² = {delta_r2:.4f}, p = {p:.4f}")

report.append("")
report.append("â†’ DASS í†µì œ í›„ UCLAì˜ ê³ ìœ  ì˜ˆì¸¡ë ¥ ì „ë¬´ (ëª¨ë“  p > 0.4)")
report.append("")

# PART 3: Gender Moderation â­ KEY FINDING
report.append("PART 3: ì„±ë³„ ì¡°ì ˆíš¨ê³¼ â­â­â­")
report.append("-" * 80)
report.append("")
report.append("3.1 WCST ë³´ì†ì˜¤ë¥˜ìœ¨ì—ì„œ UCLA Ã— Gender ìƒí˜¸ì‘ìš©")
report.append("")

wcst_row = gender_simple_slopes[gender_simple_slopes['outcome'] == 'WCST Perseverative Error Rate'].iloc[0]
wcst_perm = gender_permutation[gender_permutation['outcome'] == 'WCST'].iloc[0]
wcst_boot = gender_bootstrap[gender_bootstrap['outcome'] == 'WCST'].iloc[0]

report.append(f"  ì—¬ì„± slope: Î² = {wcst_row['beta_female']:.4f}, p = {wcst_row['p_female']:.4f}")
report.append(f"  ë‚¨ì„± slope: Î² = {wcst_row['beta_male']:.4f}, p = {wcst_row['p_male']:.4f}")
report.append(f"  ìƒí˜¸ì‘ìš©: Î² = {wcst_row['beta_interaction']:.4f}, p = {wcst_row['p_interaction']:.4f}")
report.append("")
report.append(f"  Permutation test: p = {wcst_perm['p_permutation']:.4f} ***")
report.append(f"  Bootstrap 95% CI: [{wcst_boot['boot_ci_lower']:.4f}, {wcst_boot['boot_ci_upper']:.4f}]")
report.append(f"  (CIê°€ 0 ì œì™¸: {wcst_boot['excludes_zero']})")
report.append("")
report.append("â†’ ë‚¨ì„±ì—ì„œ ì™¸ë¡œì›€â†‘ â†’ ë³´ì†ì˜¤ë¥˜â†‘ (Î²=2.29, p=0.068)")
report.append("â†’ ì—¬ì„±ì—ì„œëŠ” ê´€ê³„ ì—†ìŒ (Î²=-0.30, p=0.724)")
report.append("â†’ ìƒí˜¸ì‘ìš© ë§¤ìš° ìœ ì˜ (p=0.004, permutation p=0.004)")
report.append("")

report.append("3.2 ì„±ë³„ë³„ ìƒê´€ê³„ìˆ˜")
report.append("")

for gender in ['Female', 'Male']:
    gender_label = 'ì—¬ì„±' if gender == 'Female' else 'ë‚¨ì„±'
    subset = ultradeep_gender[ultradeep_gender['gender'] == gender_label]

    report.append(f"  {gender_label}:")
    for _, row in subset.iterrows():
        if row['outcome'] == 'WCST ë³´ì†ì˜¤ë¥˜ìœ¨':
            report.append(f"    WCST: r = {row['pearson_r']:.3f}, p = {row['pearson_p']:.3f}")

report.append("")

# PART 4: Reliability Correction
report.append("PART 4: ì‹ ë¢°ë„ ë³´ì •")
report.append("-" * 80)
report.append("")
report.append("4.1 ì¸¡ì • ì‹ ë¢°ë„ (Spearman-Brown corrected)")
report.append("")

for _, row in disattenuated.iterrows():
    task = row['task'].upper()
    rel = row['reliability_task']
    report.append(f"  {task}: r = {rel:.3f}")

report.append("")
report.append("â†’ Stroop (0.58), PRP (0.54), WCST (0.60) - ëª¨ë‘ ë‚®ì€ ì‹ ë¢°ë„")
report.append("")

report.append("4.2 ì‹ ë¢°ë„ ë³´ì • í›„ ìƒê´€")
report.append("")

for _, row in disattenuated.iterrows():
    task = row['task'].upper()
    r_obs = row['r_observed']
    r_true = row['r_disattenuated']
    report.append(f"  {task}: r_obs = {r_obs:.3f} â†’ r_true = {r_true:.3f}")

report.append("")
report.append("â†’ ë³´ì • í›„ì—ë„ íš¨ê³¼í¬ê¸° ì‘ìŒ (|r| < 0.15)")
report.append("")

report.append("4.3 ê²€ì •ë ¥ (ë³´ì •ëœ íš¨ê³¼í¬ê¸° ê¸°ì¤€)")
report.append("")

for _, row in power_corrected.iterrows():
    if not pd.isna(row['n_required_true']):
        task = row['task'].upper()
        n_req = int(row['n_required_true'])
        report.append(f"  {task}: N = {n_req} í•„ìš” (í˜„ì¬ N=72)")

report.append("")
report.append("â†’ WCST ì§„ì • íš¨ê³¼ íƒì§€ì— N=401 í•„ìš” (power=0.80, Î±=0.05)")
report.append("")

# PART 5: Latent Profiles
report.append("PART 5: Latent Profile Analysis")
report.append("-" * 80)
report.append("")
report.append("5.1 ìµœì  í”„ë¡œíŒŒì¼ ìˆ˜: k=4 (BIC ê¸°ì¤€)")
report.append("")

report.append("  Profile 1 (ì €ì™¸ë¡œì›€-ì €ìš°ìš¸): 45.8%")
report.append("  Profile 2-4 (ê³ ì™¸ë¡œì›€ ë³€í˜•): 54.2%")
report.append("")

report.append("5.2 í”„ë¡œíŒŒì¼ ê°„ EF ì°¨ì´")
report.append("")

for _, row in lpa_anova.iterrows():
    ef = row['ef_variable']
    p = row['p_value']
    eta = row['eta_squared']
    sig = "***" if p < 0.05 else "**" if p < 0.10 else ""
    report.append(f"  {ef}: p = {p:.4f}, Î·Â² = {eta:.3f} {sig}")

report.append("")
report.append("â†’ í”„ë¡œíŒŒì¼ ê°„ EF ì°¨ì´ ë¯¸ë¯¸ (ëª¨ë‘ p > 0.10)")
report.append("")

# PART 6: Trial Variability
report.append("PART 6: Trial-level ë³€ë™ì„±")
report.append("-" * 80)
report.append("")
report.append("6.1 IIV (Intra-individual Variability)")
report.append("")

for _, row in iiv_corr.iterrows():
    var = row['variable']
    r = row['pearson_r']
    p = row['pearson_p']
    report.append(f"  {var}: r = {r:.3f}, p = {p:.4f}")

report.append("")
report.append("â†’ ì™¸ë¡œì›€ê³¼ RT ë³€ë™ì„± ê°„ ìƒê´€ ì—†ìŒ")
report.append("")

report.append("6.2 Post-Error Slowing")
report.append("")

for _, row in pes_corr.iterrows():
    var = row['variable']
    r = row['pearson_r']
    p = row['pearson_p']
    report.append(f"  {var}: r = {r:.3f}, p = {p:.4f}")

report.append("")
report.append("â†’ ì™¸ë¡œì›€ê³¼ ì˜¤ë¥˜ í›„ ì¡°ì ˆ ê°„ ìƒê´€ ì—†ìŒ")
report.append("")

# PART 7: Robustness
report.append("PART 7: Robustness Checks")
report.append("-" * 80)
report.append("")
report.append("7.1 ë¹„ì„ í˜• ê´€ê³„ ê²€ì •")
report.append("")

for _, row in ultradeep_nonlinear.iterrows():
    outcome = row['outcome']
    lr_p = row['lr_p']
    sig = "***" if lr_p < 0.05 else "**" if lr_p < 0.10 else ""
    report.append(f"  {outcome}: LR test p = {lr_p:.4f} {sig}")

report.append("")
report.append("â†’ PRPì—ì„œ 2ì°¨ ê´€ê³„ marginal (p=0.087)")
report.append("")

report.append("7.2 Robust Regression (outlier ë¯¼ê°ë„)")
report.append("")

for _, row in ultradeep_robust.iterrows():
    outcome = row['outcome']
    pct_change = row['percent_change']
    if not pd.isna(pct_change):
        report.append(f"  {outcome}: ê³„ìˆ˜ ë³€í™” {pct_change:.1f}%")

report.append("")
report.append("â†’ ëª¨ë“  ë¶„ì„ì—ì„œ outlier ì˜í–¥ í¼ (20% ì´ìƒ ë³€í™”)")
report.append("")

# PART 8: Summary
report.append("PART 8: ì¢…í•© ê²°ë¡ ")
report.append("=" * 80)
report.append("")
report.append("âœ… í™•ì¸ëœ íš¨ê³¼:")
report.append("")
report.append("  1. **ì„±ë³„ ì¡°ì ˆíš¨ê³¼** (WCST):")
report.append("     - ìƒí˜¸ì‘ìš© p=0.004 (permutation p=0.004)")
report.append("     - Bootstrap 95% CI = [0.80, 4.50] (0 ì œì™¸)")
report.append("     - ë‚¨ì„±ì—ì„œë§Œ ì™¸ë¡œì›€ â†’ ë³´ì†ì˜¤ë¥˜ ê´€ê³„ (Î²=2.29, p=0.068)")
report.append("     - ì—¬ì„±ì—ì„œëŠ” ê´€ê³„ ì—†ìŒ")
report.append("")

report.append("âŒ ë¯¸í™•ì¸/ë¶ˆì¶©ë¶„í•œ ì¦ê±°:")
report.append("")
report.append("  1. **ì£¼íš¨ê³¼**: UCLA â†’ EF ì§ì ‘ íš¨ê³¼ ì—†ìŒ (ëª¨ë“  |r| < 0.10)")
report.append("  2. **DASS í†µì œ í›„**: ê³ ìœ  ì˜ˆì¸¡ë ¥ ì „ë¬´ (ëª¨ë“  Î”RÂ² < 0.01)")
report.append("  3. **ê·¹ë‹¨ì§‘ë‹¨**: ê³ ì™¸ë¡œì›€ vs ì €ì™¸ë¡œì›€ EF ì°¨ì´ ì—†ìŒ")
report.append("  4. **Latent profiles**: í”„ë¡œíŒŒì¼ ê°„ EF ì°¨ì´ ì—†ìŒ")
report.append("  5. **Trial variability**: IIV, PESì™€ ì™¸ë¡œì›€ ë¬´ê´€")
report.append("")

report.append("âš ï¸  ë°©ë²•ë¡ ì  í•œê³„:")
report.append("")
report.append("  1. **ì‘ì€ ìƒ˜í”Œ**: N=72 (ì„±ë³„ ì¸µí™” ì‹œ ë‚¨ì„± N=27)")
report.append("  2. **ë‚®ì€ ì‹ ë¢°ë„**: EF ê³¼ì œ r=0.54~0.60")
report.append("  3. **íš¡ë‹¨ ì„¤ê³„**: ì¸ê³¼ê´€ê³„ ë¶ˆëª…")
report.append("  4. **Outlier ì˜í–¥**: Robust regressionì—ì„œ í° ë³€í™”")
report.append("")

report.append("ğŸ’¡ í–¥í›„ ì—°êµ¬ ê¶Œì¥ì‚¬í•­:")
report.append("")
report.append("  1. **ì„±ë³„ ì¡°ì ˆíš¨ê³¼ ì¬í˜„ ì—°êµ¬**:")
report.append("     - Nâ‰¥150 ëª©í‘œ (power=0.80)")
report.append("     - ì‚¬ì „ë“±ë¡ í™•ì¦ ì—°êµ¬")
report.append("     - ì‹¤í—˜ì‹¤ í™˜ê²½ (ì‹ ë¢°ë„ í–¥ìƒ)")
report.append("")
report.append("  2. **ì´ë¡ ì  ë©”ì»¤ë‹ˆì¦˜ íƒìƒ‰**:")
report.append("     - ì™œ ë‚¨ì„±ì—ì„œë§Œ íš¨ê³¼?")
report.append("     - ì‚¬íšŒì  ê³ ë¦½ vs ì£¼ê´€ì  ì™¸ë¡œì›€ êµ¬ë¶„")
report.append("     - ìŠ¤íŠ¸ë ˆìŠ¤ ë°˜ì‘ ì„±ì°¨")
report.append("")
report.append("  3. **ì¸¡ì • ê°œì„ **:")
report.append("     - ê³¼ì œ ì‹œí–‰ìˆ˜ ì¦ê°€ (ì‹ ë¢°ë„ í–¥ìƒ)")
report.append("     - ì‹¤í—˜ì‹¤ vs ì˜¨ë¼ì¸ ë¹„êµ")
report.append("     - ì¢…ë‹¨ ì„¤ê³„ (ì¸ê³¼ê´€ê³„)")
report.append("")

report.append("ğŸ“Š ë…¼ë¬¸ ì‘ì„± ì „ëµ:")
report.append("")
report.append("  **ì˜µì…˜ A (ì¶”ì²œ)**: ì„±ë³„ ì¡°ì ˆíš¨ê³¼ ë…¼ë¬¸")
report.append("    - Title: \"Gender Moderates Loneliness-Cognitive Flexibility Link\"")
report.append("    - Target: Sex Roles, Psychology of Men & Masculinities (Q2)")
report.append("    - ì´ˆì : ë‚¨ì„± ì™¸ë¡œì›€ì˜ ì¸ì§€ì  ê²°ê³¼")
report.append("    - ê°•ì : ìœ ì˜í•œ ë°œê²¬, ì´ë¡ ì  í•¨ì˜")
report.append("    - ì•½ì : í™•ì¦ ì—°êµ¬ í•„ìš”")
report.append("")
report.append("  **ì˜µì…˜ B**: Null ê²°ê³¼ ë…¼ë¬¸")
report.append("    - Title: \"Minimal Evidence for Loneliness-EF Association\"")
report.append("    - Target: PLOS ONE, Collabra (open science)")
report.append("    - ì´ˆì : íˆ¬ëª…í•œ ë³´ê³ , ë‹¤ê°ì  ë°©ë²•ë¡ ")
report.append("    - ê°•ì : Robustness checks ì¶©ì‹¤")
report.append("    - ì•½ì : ê´€ì‹¬ë„ ë‚®ì„ ìˆ˜ ìˆìŒ")
report.append("")
report.append("  **ì˜µì…˜ C**: ì¸¡ì • ì‹ ë¢°ë„ ë°©ë²•ë¡  ë…¼ë¬¸")
report.append("    - Title: \"Reliability Constraints in Online Cognitive Testing\"")
report.append("    - Target: Behavior Research Methods (Q1)")
report.append("    - ì´ˆì : ì˜¨ë¼ì¸ ì—°êµ¬ í•œê³„ì™€ í•´ê²°ì±…")
report.append("    - ê°•ì : ë°©ë²•ë¡ ì  ê¸°ì—¬")
report.append("    - ì•½ì : ì‹¤ì§ˆ ë°œê²¬ ì ìŒ")
report.append("")

report.append("=" * 80)
report.append("ë¦¬í¬íŠ¸ ì‘ì„± ì™„ë£Œ")
report.append("=" * 80)

# Save report
report_text = "\n".join(report)

with open(OUTPUT_DIR / "COMPREHENSIVE_SUMMARY_REPORT.txt", "w", encoding="utf-8") as f:
    f.write(report_text)

print(report_text)

print("\n\n")
print("=" * 80)
print("ë¦¬í¬íŠ¸ ì €ì¥ ì™„ë£Œ")
print(f"ìœ„ì¹˜: {OUTPUT_DIR / 'COMPREHENSIVE_SUMMARY_REPORT.txt'}")
print("=" * 80)

# Create CSV summary table
summary_table = pd.DataFrame({
    'Analysis': [
        'ì£¼íš¨ê³¼ (zero-order)',
        'ìœ„ê³„ì  íšŒê·€ (DASS í†µì œ)',
        'ì„±ë³„ ì¡°ì ˆíš¨ê³¼ (WCST)',
        'ì‹ ë¢°ë„ ë³´ì •',
        'Latent profiles',
        'Trial variability',
        'ë¹„ì„ í˜• (PRP)',
        'Robust regression'
    ],
    'Key Finding': [
        'ëª¨ë“  |r| < 0.10',
        'ëª¨ë“  Î”RÂ² < 0.01, p > 0.4',
        'ìƒí˜¸ì‘ìš© p=0.004 ***',
        'r_true = -0.14 (WCST)',
        'í”„ë¡œíŒŒì¼ ê°„ ì°¨ì´ ì—†ìŒ',
        'IIV/PESì™€ ë¬´ê´€',
        'LR p=0.087 (marginal)',
        '20-67% ê³„ìˆ˜ ë³€í™”'
    ],
    'Conclusion': [
        'íš¨ê³¼ ì—†ìŒ',
        'íš¨ê³¼ ì—†ìŒ',
        'ë‚¨ì„±ì—ì„œ ìœ ì˜í•œ ì¡°ì ˆ',
        'ì§„ì • íš¨ê³¼ë„ ì‘ìŒ',
        'ì¡°í•© íš¨ê³¼ ì—†ìŒ',
        'íš¨ê³¼ ì—†ìŒ',
        'ê°€ëŠ¥ì„±ë§Œ ì‹œì‚¬',
        'Outlier ì˜í–¥ í¼'
    ]
})

summary_table.to_csv(OUTPUT_DIR / "summary_table.csv", index=False, encoding='utf-8-sig')

print(f"ìš”ì•½ í…Œì´ë¸”: {OUTPUT_DIR / 'summary_table.csv'}")
