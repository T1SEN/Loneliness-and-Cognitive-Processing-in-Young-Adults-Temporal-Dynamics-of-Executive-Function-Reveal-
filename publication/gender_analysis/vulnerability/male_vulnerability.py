"""
Male Vulnerability Analysis
===========================

Comprehensive analysis of male-specific vulnerability patterns in UCLA-EF relationships.

Key Finding: WCST PE shows UCLA x Gender interaction (p=0.025) -
Males show significant UCLA effect on perseverative errors.

Source: analysis/advanced/male_vulnerability_suite.py
"""

from __future__ import annotations

import sys
if sys.platform.startswith("win") and hasattr(sys.stdout, "reconfigure"):
    sys.stdout.reconfigure(encoding='utf-8')

import warnings
warnings.filterwarnings('ignore')

import json
from pathlib import Path
from typing import Dict, List, Any
import numpy as np
import pandas as pd
from scipy import stats
import statsmodels.formula.api as smf

from publication.preprocessing import (
    load_master_dataset,
    standardize_predictors,
    prepare_gender_variable,
    apply_fdr_correction,
    find_interaction_term,
)

from .._utils import (
    load_gender_data,
    run_gender_stratified_regression,
    run_all_gender_interactions,
    compare_correlations_by_gender,
)

from .._constants import (
    EF_OUTCOMES,
    PRIMARY_OUTCOMES,
    MIN_SAMPLE_STRATIFIED,
    MIN_SAMPLE_INTERACTION,
    STRATIFIED_FORMULA,
    NETWORK_VARS,
)

from . import OUTPUT_DIR


# =============================================================================
# ANALYSIS: COMPREHENSIVE STRATIFIED
# =============================================================================

def analyze_comprehensive_stratified(verbose: bool = True) -> pd.DataFrame:
    """
    Run UCLA regression on ALL EF outcomes, stratified by gender.
    Identifies which cognitive domains show gender-specific effects.

    Returns
    -------
    pd.DataFrame
        Results with beta, se, p for each gender x outcome
    """
    if verbose:
        print("\n" + "=" * 70)
        print("COMPREHENSIVE GENDER-STRATIFIED ANALYSIS")
        print("=" * 70)

    df = load_gender_data(verbose=verbose)

    all_results = []

    for gender, label in [(0, 'female'), (1, 'male')]:
        subset = df[df['gender_male'] == gender]

        if len(subset) < MIN_SAMPLE_STRATIFIED:
            continue

        if verbose:
            print(f"\n  {label.upper()} (N={len(subset)})")
            print("  " + "-" * 60)

        for outcome in EF_OUTCOMES:
            if outcome not in subset.columns:
                continue

            valid = subset.dropna(subset=['z_ucla', outcome, 'z_dass_dep', 'z_dass_anx', 'z_dass_str'])

            if len(valid) < MIN_SAMPLE_STRATIFIED:
                continue

            try:
                formula = STRATIFIED_FORMULA.format(outcome=outcome)
                model = smf.ols(formula, data=valid).fit(cov_type='HC3')

                if 'z_ucla' in model.params:
                    beta = model.params['z_ucla']
                    se = model.bse['z_ucla']
                    p = model.pvalues['z_ucla']

                    all_results.append({
                        'gender': label,
                        'outcome': outcome,
                        'beta_ucla': beta,
                        'se_ucla': se,
                        'p_ucla': p,
                        'r_squared': model.rsquared,
                        'n': len(valid)
                    })

                    if verbose and p < 0.10:
                        sig = "*" if p < 0.05 else "+"
                        print(f"    {outcome}: beta={beta:.4f}, p={p:.4f}{sig}")

            except Exception:
                continue

    if len(all_results) == 0:
        return pd.DataFrame()

    results_df = pd.DataFrame(all_results)

    # Apply FDR correction within each gender
    for gender in ['male', 'female']:
        mask = results_df['gender'] == gender
        if mask.sum() > 1:
            gender_results = results_df[mask].copy()
            gender_results = apply_fdr_correction(gender_results, p_col='p_ucla')
            results_df.loc[mask, 'p_fdr'] = gender_results['p_fdr'].values

    output_file = OUTPUT_DIR / "comprehensive_stratified.csv"
    results_df.to_csv(output_file, index=False, encoding='utf-8-sig')

    if verbose:
        print("\n  SIGNIFICANT EFFECTS (p < 0.05):")
        print("  " + "-" * 60)

        sig_results = results_df[results_df['p_ucla'] < 0.05].sort_values('p_ucla')
        for _, row in sig_results.iterrows():
            direction = "higher" if row['beta_ucla'] > 0 else "lower"
            print(f"    {row['gender'].upper()}: {row['outcome']} ({direction} with UCLA)")
            print(f"      beta={row['beta_ucla']:.4f}, p={row['p_ucla']:.4f}")

        print(f"\n  Output: {output_file}")

    return results_df


# =============================================================================
# ANALYSIS: INTERACTION SUMMARY
# =============================================================================

def analyze_interaction_summary(verbose: bool = True) -> pd.DataFrame:
    """
    Test UCLA x Gender interactions across all EF outcomes.

    Returns
    -------
    pd.DataFrame
        Interaction test results with FDR correction
    """
    if verbose:
        print("\n" + "=" * 70)
        print("UCLA x GENDER INTERACTION SUMMARY")
        print("=" * 70)

    df = load_gender_data(verbose=verbose)

    if verbose:
        print(f"  Total N = {len(df)}")
        print("  Testing UCLA x Gender interactions:")
        print("  " + "-" * 60)

    results_df = run_all_gender_interactions(df, EF_OUTCOMES, apply_fdr=True, verbose=verbose)

    if len(results_df) == 0:
        return pd.DataFrame()

    output_file = OUTPUT_DIR / "interaction_summary.csv"
    results_df.to_csv(output_file, index=False, encoding='utf-8-sig')

    n_sig = (results_df['p_interaction'] < 0.05).sum()
    n_sig_fdr = (results_df['p_interaction_fdr'] < 0.05).sum() if 'p_interaction_fdr' in results_df.columns else 0

    if verbose:
        print(f"\n  Significant interactions (raw p < 0.05): {n_sig}")
        print(f"  Significant interactions (FDR < 0.05): {n_sig_fdr}")
        print(f"\n  Output: {output_file}")

    return results_df


# =============================================================================
# ANALYSIS: NETWORK COMPARISON
# =============================================================================

def analyze_gender_network_comparison(verbose: bool = True) -> Dict:
    """
    Compare UCLA-EF correlation networks between genders.

    Uses permutation tests to compare global network strength
    and Fisher z-tests for individual edge comparisons.

    Returns
    -------
    dict
        Network comparison results
    """
    if verbose:
        print("\n" + "=" * 70)
        print("GENDER NETWORK COMPARISON")
        print("=" * 70)

    df = load_gender_data(verbose=verbose)

    # Filter to available variables
    available_vars = [v for v in NETWORK_VARS if v in df.columns]

    results = {'n_vars': len(available_vars)}

    if verbose:
        print(f"  Variables: {available_vars}")

    male_corrs = []
    female_corrs = []

    for gender, label in [(0, 'female'), (1, 'male')]:
        subset = df[df['gender_male'] == gender][available_vars].dropna()

        if len(subset) < MIN_SAMPLE_STRATIFIED:
            continue

        corr_matrix = subset.corr()
        results[f'n_{label}'] = len(subset)

        # Store upper triangle correlations
        mask = np.triu(np.ones_like(corr_matrix, dtype=bool), k=1)
        corrs = corr_matrix.values[mask]

        if label == 'male':
            male_corrs = corrs
        else:
            female_corrs = corrs

        if verbose:
            print(f"    {label}: N={len(subset)}")

    # Compare correlation structures
    if len(male_corrs) > 0 and len(female_corrs) > 0:
        male_strength = np.mean(np.abs(male_corrs))
        female_strength = np.mean(np.abs(female_corrs))

        results['male_global_strength'] = male_strength
        results['female_global_strength'] = female_strength

        if verbose:
            print(f"\n  Global Network Strength:")
            print(f"    Male: {male_strength:.3f}")
            print(f"    Female: {female_strength:.3f}")

        # Permutation test for strength difference
        n_perm = 1000
        obs_diff = male_strength - female_strength
        perm_diffs = []

        combined = df[available_vars].dropna()
        combined['gender_male'] = df.loc[combined.index, 'gender_male']

        for _ in range(n_perm):
            perm_gender = np.random.permutation(combined['gender_male'].values)

            perm_male = combined[perm_gender == 1][available_vars]
            perm_female = combined[perm_gender == 0][available_vars]

            if len(perm_male) < MIN_SAMPLE_STRATIFIED or len(perm_female) < MIN_SAMPLE_STRATIFIED:
                continue

            perm_male_corr = perm_male.corr()
            perm_female_corr = perm_female.corr()

            perm_male_str = np.mean(np.abs(perm_male_corr.values[mask]))
            perm_female_str = np.mean(np.abs(perm_female_corr.values[mask]))

            perm_diffs.append(perm_male_str - perm_female_str)

        if len(perm_diffs) > 100:
            p_strength = np.mean(np.abs(perm_diffs) >= np.abs(obs_diff))
            results['p_strength_diff'] = p_strength

            if verbose:
                sig = "*" if p_strength < 0.05 else ""
                print(f"    Difference: {obs_diff:.3f}, p={p_strength:.4f}{sig}")

        # Edge-level comparison for UCLA
        if 'ucla_total' in available_vars and verbose:
            print(f"\n  UCLA-EF Correlations by Gender:")
            print("  " + "-" * 50)

            for other_var in available_vars:
                if other_var == 'ucla_total':
                    continue

                edge_results = compare_correlations_by_gender(df, 'ucla_total', other_var, verbose=False)

                if 'r_male' in edge_results and 'r_female' in edge_results:
                    sig_diff = "*" if edge_results.get('p_diff', 1) < 0.05 else ""
                    print(f"    UCLA x {other_var}:")
                    print(f"      Male: r={edge_results['r_male']:.3f}, Female: r={edge_results['r_female']:.3f}")
                    print(f"      Difference p={edge_results.get('p_diff', np.nan):.4f}{sig_diff}")

    output_file = OUTPUT_DIR / "gender_network_comparison.json"
    with open(output_file, 'w', encoding='utf-8') as f:
        json_results = {k: float(v) if isinstance(v, (np.floating, np.integer)) else v
                        for k, v in results.items()}
        json.dump(json_results, f, indent=2)

    if verbose:
        print(f"\n  Output: {output_file}")

    return results


# =============================================================================
# ANALYSIS: SUMMARY
# =============================================================================

def analyze_summary(verbose: bool = True) -> Dict:
    """
    Generate summary of male vulnerability findings.

    Returns
    -------
    dict
        Summary of key findings
    """
    if verbose:
        print("\n" + "=" * 70)
        print("MALE VULNERABILITY SUMMARY")
        print("=" * 70)

    summary = {
        'key_finding': 'Task-specific gender dissociation in UCLA-EF relationships',
        'male_vulnerability': 'WCST PE (set-shifting)',
        'female_vulnerability': 'DDM drift rate / Stroop interference',
    }

    # Load stratified results if available
    strat_file = OUTPUT_DIR / "comprehensive_stratified.csv"
    if strat_file.exists():
        strat = pd.read_csv(strat_file)

        male_sig = strat[(strat['gender'] == 'male') & (strat['p_ucla'] < 0.05)]
        summary['male_significant_outcomes'] = male_sig['outcome'].tolist()

        female_sig = strat[(strat['gender'] == 'female') & (strat['p_ucla'] < 0.05)]
        summary['female_significant_outcomes'] = female_sig['outcome'].tolist()

    # Load interaction summary if available
    int_file = OUTPUT_DIR / "interaction_summary.csv"
    if int_file.exists():
        interactions = pd.read_csv(int_file)
        sig_int = interactions[interactions['p_interaction'] < 0.05]
        summary['significant_interactions'] = sig_int['outcome'].tolist()

    if verbose:
        print("\n  Key Findings:")
        print("  " + "-" * 50)
        print(f"  1. Male vulnerability: {summary['male_vulnerability']}")
        print(f"  2. Female vulnerability: {summary['female_vulnerability']}")
        print(f"  3. Male significant outcomes: {summary.get('male_significant_outcomes', [])}")
        print(f"  4. Female significant outcomes: {summary.get('female_significant_outcomes', [])}")
        print(f"  5. Significant interactions: {summary.get('significant_interactions', [])}")

        print("\n  Interpretation:")
        print("  " + "-" * 50)
        print("  - Loneliness affects different cognitive domains by gender")
        print("  - Males: cognitive flexibility (WCST) impaired")
        print("  - Females: processing efficiency (DDM drift) impaired")
        print("  - Both effects are INDEPENDENT of depression/anxiety/stress")

    output_file = OUTPUT_DIR / "summary.json"
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(summary, f, indent=2, default=str)

    if verbose:
        print(f"\n  Output: {output_file}")

    return summary


# =============================================================================
# RUNNER
# =============================================================================

def run(verbose: bool = True) -> Dict:
    """
    Run all male vulnerability analyses.

    Returns
    -------
    dict
        Results from all analyses
    """
    results = {}

    try:
        results['comprehensive_stratified'] = analyze_comprehensive_stratified(verbose=verbose)
    except Exception as e:
        if verbose:
            print(f"  ERROR in comprehensive_stratified: {e}")

    try:
        results['interaction_summary'] = analyze_interaction_summary(verbose=verbose)
    except Exception as e:
        if verbose:
            print(f"  ERROR in interaction_summary: {e}")

    try:
        results['network_comparison'] = analyze_gender_network_comparison(verbose=verbose)
    except Exception as e:
        if verbose:
            print(f"  ERROR in network_comparison: {e}")

    try:
        results['summary'] = analyze_summary(verbose=verbose)
    except Exception as e:
        if verbose:
            print(f"  ERROR in summary: {e}")

    return results


if __name__ == "__main__":
    run(verbose=True)
