"""
Individual Vulnerability Profiles Analysis
============================================
Identifies vulnerable vs resilient males with high loneliness
"""

import sys
if sys.platform.startswith("win") and hasattr(sys.stdout, "reconfigure"):
    sys.stdout.reconfigure(encoding='utf-8')

import pandas as pd
import numpy as np
from pathlib import Path
from scipy import stats
import warnings
warnings.filterwarnings('ignore')

# Import our data loader
from data_loader_utils import load_master_dataset, load_exgaussian_params

# ============================================================================
# Configuration
# ============================================================================

OUTPUT_DIR = Path("results/analysis_outputs/individual_profiles")
OUTPUT_DIR.mkdir(exist_ok=True, parents=True)

print("=" * 80)
print("INDIVIDUAL VULNERABILITY PROFILES ANALYSIS")
print("=" * 80)

# ============================================================================
# Load Data
# ============================================================================

print("\nLoading data...")
master = load_master_dataset()

# Load Ex-Gaussian params
try:
    prp_exg = load_exgaussian_params('prp')
    master = master.merge(prp_exg[['participant_id', 'long_tau', 'long_sigma', 'short_tau']],
                          on='participant_id', how='left')
    master = master.rename(columns={'long_tau': 'prp_tau_long', 'long_sigma': 'prp_sigma_long',
                                     'short_tau': 'prp_tau_short'})
except:
    print("  Warning: Could not load PRP Ex-Gaussian parameters")

try:
    stroop_exg = load_exgaussian_params('stroop')
    master = master.merge(stroop_exg[['participant_id', 'tau', 'sigma']],
                          on='participant_id', how='left', suffixes=('', '_stroop'))
except:
    print("  Warning: Could not load Stroop Ex-Gaussian parameters")

# Drop missing
master = master.dropna(subset=['ucla_total', 'gender_male', 'pe_rate']).copy()

print(f"  Loaded {len(master)} participants with complete data")
print(f"  Males: {master['gender_male'].sum()}, Females: {(1-master['gender_male']).sum()}\n")

# ============================================================================
# Define Profiles (Males Only)
# ============================================================================

print("=" * 80)
print("DEFINING VULNERABILITY PROFILES (Males Only)")
print("=" * 80)

males = master[master['gender_male'] == 1].copy()
print(f"\nTotal males: {len(males)}")

# Calculate thresholds
ucla_median = males['ucla_total'].median()
pe_75 = males['pe_rate'].quantile(0.75)
pe_25 = males['pe_rate'].quantile(0.25)

print(f"\nThresholds:")
print(f"  UCLA median: {ucla_median:.1f}")
print(f"  PE 75th percentile: {pe_75:.1f}%")
print(f"  PE 25th percentile: {pe_25:.1f}%")

# Assign profiles
def assign_profile(row):
    if row['ucla_total'] > ucla_median:
        if row['pe_rate'] > pe_75:
            return 'Vulnerable'
        elif row['pe_rate'] < pe_25:
            return 'Resilient'
        else:
            return 'Moderate'
    else:
        return 'Control'

males['profile'] = males.apply(assign_profile, axis=1)

# Count profiles
profile_counts = males['profile'].value_counts()
print(f"\nProfile distribution:")
for profile, count in profile_counts.items():
    print(f"  {profile}: {count}")

# Filter to key groups
key_groups = males[males['profile'].isin(['Vulnerable', 'Resilient', 'Control'])].copy()

print(f"\nComparing {len(key_groups)} males across 3 profiles:")
for profile in ['Vulnerable', 'Resilient', 'Control']:
    n = (key_groups['profile'] == profile).sum()
    print(f"  {profile}: {n}")

# ============================================================================
# Compare Groups
# ============================================================================

print("\n" + "=" * 80)
print("GROUP COMPARISONS")
print("=" * 80)

comparison_vars = [
    'ucla_total', 'pe_rate', 'wcst_accuracy', 'wcst_sd_rt',
    'dass_depression', 'dass_anxiety', 'dass_stress',
    'age', 'prp_tau_long', 'prp_sigma_long', 'stroop_interference'
]

# Descriptive stats
desc_stats = []
for var in comparison_vars:
    if var not in key_groups.columns:
        continue

    for profile in ['Vulnerable', 'Resilient', 'Control']:
        data = key_groups[key_groups['profile'] == profile][var].dropna()
        if len(data) > 0:
            desc_stats.append({
                'variable': var,
                'profile': profile,
                'n': len(data),
                'mean': data.mean(),
                'sd': data.std(),
                'median': data.median()
            })

desc_df = pd.DataFrame(desc_stats)

# Kruskal-Wallis tests
anova_results = []
for var in comparison_vars:
    if var not in key_groups.columns:
        continue

    vulnerable = key_groups[key_groups['profile'] == 'Vulnerable'][var].dropna()
    resilient = key_groups[key_groups['profile'] == 'Resilient'][var].dropna()
    control = key_groups[key_groups['profile'] == 'Control'][var].dropna()

    if len(vulnerable) >= 3 and len(resilient) >= 3 and len(control) >= 3:
        try:
            h_stat, p_val = stats.kruskal(vulnerable, resilient, control)
            anova_results.append({
                'variable': var,
                'h_statistic': h_stat,
                'p_value': p_val,
                'vulnerable_mean': vulnerable.mean(),
                'resilient_mean': resilient.mean(),
                'control_mean': control.mean()
            })
        except:
            pass

anova_df = pd.DataFrame(anova_results)

# Print key findings
print("\nSignificant group differences (p < 0.05):")
if len(anova_df) > 0:
    sig_vars = anova_df[anova_df['p_value'] < 0.05].sort_values('p_value')

    if len(sig_vars) > 0:
        for _, row in sig_vars.iterrows():
            print(f"\n  {row['variable']}:")
            print(f"    H = {row['h_statistic']:.2f}, p = {row['p_value']:.4f}")
            print(f"    Vulnerable: {row['vulnerable_mean']:.2f}")
            print(f"    Resilient: {row['resilient_mean']:.2f}")
            print(f"    Control: {row['control_mean']:.2f}")
    else:
        print("  None at p < 0.05")
else:
    print("  Insufficient data for comparisons")

# ============================================================================
# Logistic Regression
# ============================================================================

print("\n\n" + "=" * 80)
print("LOGISTIC REGRESSION: Vulnerable vs Resilient")
print("=" * 80)

vul_res = key_groups[key_groups['profile'].isin(['Vulnerable', 'Resilient'])].copy()
vul_res['is_vulnerable'] = (vul_res['profile'] == 'Vulnerable').astype(int)

predictor_cols = ['dass_depression', 'dass_anxiety', 'dass_stress', 'age']
available_predictors = [col for col in predictor_cols if col in vul_res.columns]

vul_res_clean = vul_res.dropna(subset=available_predictors + ['is_vulnerable']).copy()

if len(vul_res_clean) >= 10:
    from sklearn.linear_model import LogisticRegression
    from sklearn.preprocessing import StandardScaler

    X = vul_res_clean[available_predictors].values
    y = vul_res_clean['is_vulnerable'].values

    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)

    log_reg = LogisticRegression(penalty=None, max_iter=1000)
    log_reg.fit(X_scaled, y)

    coefs = pd.DataFrame({
        'predictor': available_predictors,
        'coefficient': log_reg.coef_[0],
        'odds_ratio': np.exp(log_reg.coef_[0])
    }).sort_values('coefficient', key=abs, ascending=False)

    print(f"\nN = {len(vul_res_clean)} (Vulnerable: {y.sum()}, Resilient: {len(y) - y.sum()})")
    print("\nLogistic regression coefficients:")
    print(coefs.to_string(index=False))

    y_pred = log_reg.predict(X_scaled)
    accuracy = (y_pred == y).mean()
    print(f"\nModel accuracy: {accuracy:.2%}")
else:
    print(f"\nInsufficient data (N={len(vul_res_clean)})")
    coefs = pd.DataFrame()

# ============================================================================
# Save Results
# ============================================================================

print("\n\nSaving results...")

profile_file = OUTPUT_DIR / "male_vulnerability_profiles.csv"
males[['participant_id', 'profile', 'ucla_total', 'pe_rate', 'wcst_accuracy']].to_csv(
    profile_file, index=False, encoding='utf-8-sig'
)
print(f"  {profile_file}")

desc_file = OUTPUT_DIR / "profile_descriptive_stats.csv"
desc_df.to_csv(desc_file, index=False, encoding='utf-8-sig')
print(f"  {desc_file}")

anova_file = OUTPUT_DIR / "profile_group_comparisons.csv"
anova_df.to_csv(anova_file, index=False, encoding='utf-8-sig')
print(f"  {anova_file}")

if len(coefs) > 0:
    logreg_file = OUTPUT_DIR / "vulnerability_logistic_regression.csv"
    coefs.to_csv(logreg_file, index=False, encoding='utf-8-sig')
    print(f"  {logreg_file}")

print("\n" + "=" * 80)
print("ANALYSIS COMPLETE")
print("=" * 80)
