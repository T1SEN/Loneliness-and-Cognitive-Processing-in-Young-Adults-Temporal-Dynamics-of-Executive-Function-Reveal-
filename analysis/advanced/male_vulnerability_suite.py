"""
Male Vulnerability Analysis Suite
=================================

Investigates gender-specific patterns in UCLA → Executive Function relationships.

Key Findings to Explain:
- WCST PE: UCLA × Gender interaction (p=0.025) - Males show significant UCLA effect
- DDM Drift: UCLA effect significant in FEMALES (p=0.021), not males

This suite performs:
1. Comprehensive gender-stratified analyses across all EF measures
2. Network comparison between genders (NCT-like)
3. Gender-specific protective/risk factors
4. Dissociation analysis: Why different cognitive domains?

Usage:
    python -m analysis.advanced.male_vulnerability_suite

Author: Research Team
Date: 2025-12
"""

from __future__ import annotations

import sys
if sys.platform.startswith("win") and hasattr(sys.stdout, "reconfigure"):
    sys.stdout.reconfigure(encoding='utf-8')

import warnings
warnings.filterwarnings('ignore')

import argparse
from pathlib import Path
from typing import Dict, Optional, Callable, List
from dataclasses import dataclass
import numpy as np
import pandas as pd
from scipy import stats
import statsmodels.formula.api as smf

from analysis.preprocessing import (
    load_master_dataset, RESULTS_DIR, ANALYSIS_OUTPUT_DIR,
    apply_fdr_correction, find_interaction_term
)
from analysis.preprocessing.trial_loaders import load_wcst_trials
from analysis.utils.modeling import standardize_predictors

np.random.seed(42)
OUTPUT_DIR = ANALYSIS_OUTPUT_DIR / "male_vulnerability"
OUTPUT_DIR.mkdir(parents=True, exist_ok=True)


@dataclass
class AnalysisSpec:
    name: str
    description: str
    function: Callable
    source_script: str


ANALYSES: Dict[str, AnalysisSpec] = {}


def register_analysis(name: str, description: str, source_script: str = "male_vulnerability_suite.py"):
    def decorator(func: Callable):
        ANALYSES[name] = AnalysisSpec(name=name, description=description, function=func, source_script=source_script)
        return func
    return decorator


def load_master_with_standardization() -> pd.DataFrame:
    """Load master dataset with standardized predictors."""
    master = load_master_dataset(use_cache=True, merge_cognitive_summary=True)

    if 'gender_normalized' in master.columns:
        master['gender'] = master['gender_normalized'].fillna('').astype(str).str.strip().str.lower()
    else:
        master['gender'] = master['gender'].fillna('').astype(str).str.strip().str.lower()

    master['gender_male'] = (master['gender'] == 'male').astype(int)
    master = standardize_predictors(master)

    return master


# Define all EF outcome variables
EF_OUTCOMES = [
    # WCST
    'pe_rate', 'npe_rate', 'total_error_rate', 'categories_completed',
    'trials_to_first_category', 'conceptual_level_responses',
    # Stroop
    'stroop_interference', 'stroop_effect', 'stroop_acc', 'stroop_rt_mean',
    # PRP
    'prp_bottleneck', 'prp_short_rt', 'prp_long_rt', 'prp_pep_effect',
    # Derived
    'wcst_pe', 'stroop_congruent_rt', 'stroop_incongruent_rt',
]


@register_analysis("comprehensive_stratified", "Comprehensive gender-stratified UCLA effects")
def analyze_comprehensive_stratified(verbose: bool = True) -> pd.DataFrame:
    """
    Run UCLA regression on ALL EF outcomes, stratified by gender.
    Identifies which cognitive domains show gender-specific effects.
    """
    if verbose:
        print("\n" + "=" * 70)
        print("COMPREHENSIVE GENDER-STRATIFIED ANALYSIS")
        print("=" * 70)

    master = load_master_with_standardization()

    all_results = []

    for gender, label in [(0, 'female'), (1, 'male')]:
        subset = master[master['gender_male'] == gender]

        if len(subset) < 20:
            continue

        if verbose:
            print(f"\n  {label.upper()} (N={len(subset)})")
            print("  " + "-" * 60)

        for outcome in EF_OUTCOMES:
            if outcome not in subset.columns:
                continue

            valid = subset.dropna(subset=['z_ucla', outcome, 'z_dass_dep', 'z_dass_anx', 'z_dass_str'])

            if len(valid) < 15:
                continue

            try:
                formula = f"{outcome} ~ z_ucla + z_dass_dep + z_dass_anx + z_dass_str + z_age"
                model = smf.ols(formula, data=valid).fit(cov_type='HC3')

                if 'z_ucla' in model.params:
                    beta = model.params['z_ucla']
                    se = model.bse['z_ucla']
                    p = model.pvalues['z_ucla']

                    all_results.append({
                        'gender': label,
                        'outcome': outcome,
                        'beta_ucla': beta,
                        'se_ucla': se,
                        'p_ucla': p,
                        'r_squared': model.rsquared,
                        'n': len(valid)
                    })

                    if verbose and p < 0.10:
                        sig = "*" if p < 0.05 else "†"
                        print(f"    {outcome}: β={beta:.4f}, p={p:.4f}{sig}")

            except Exception:
                continue

    if len(all_results) == 0:
        return pd.DataFrame()

    results_df = pd.DataFrame(all_results)

    # Apply FDR correction within each gender
    for gender in ['male', 'female']:
        mask = results_df['gender'] == gender
        if mask.sum() > 1:
            gender_results = results_df[mask].copy()
            gender_results = apply_fdr_correction(gender_results, p_col='p_ucla')
            results_df.loc[mask, 'p_fdr'] = gender_results['p_fdr'].values

    results_df.to_csv(OUTPUT_DIR / "comprehensive_stratified.csv", index=False, encoding='utf-8-sig')

    # Summary: significant effects
    if verbose:
        print("\n  SIGNIFICANT EFFECTS (p < 0.05):")
        print("  " + "-" * 60)

        sig_results = results_df[results_df['p_ucla'] < 0.05].sort_values('p_ucla')
        for _, row in sig_results.iterrows():
            direction = "↑" if row['beta_ucla'] > 0 else "↓"
            print(f"    {row['gender'].upper()}: {row['outcome']} {direction} (β={row['beta_ucla']:.4f}, p={row['p_ucla']:.4f})")

        print(f"\n  Output: {OUTPUT_DIR / 'comprehensive_stratified.csv'}")

    return results_df


@register_analysis("interaction_summary", "Summary of all UCLA × Gender interactions")
def analyze_interaction_summary(verbose: bool = True) -> pd.DataFrame:
    """
    Test UCLA × Gender interactions across all EF outcomes.
    """
    if verbose:
        print("\n" + "=" * 70)
        print("UCLA × GENDER INTERACTION SUMMARY")
        print("=" * 70)

    master = load_master_with_standardization()

    all_results = []

    if verbose:
        print(f"\n  Total N = {len(master)}")
        print("  Testing UCLA × Gender interactions:")
        print("  " + "-" * 60)

    for outcome in EF_OUTCOMES:
        if outcome not in master.columns:
            continue

        valid = master.dropna(subset=['z_ucla', outcome, 'gender_male', 'z_dass_dep', 'z_dass_anx', 'z_dass_str'])

        if len(valid) < 30:
            continue

        try:
            formula = f"{outcome} ~ z_ucla * C(gender_male) + z_dass_dep + z_dass_anx + z_dass_str + z_age"
            model = smf.ols(formula, data=valid).fit(cov_type='HC3')

            # Main effect
            beta_main = model.params.get('z_ucla', np.nan)
            p_main = model.pvalues.get('z_ucla', np.nan)

            # Interaction
            int_term = find_interaction_term(model.params.index)
            beta_int = model.params.get(int_term, np.nan) if int_term else np.nan
            p_int = model.pvalues.get(int_term, np.nan) if int_term else np.nan

            all_results.append({
                'outcome': outcome,
                'beta_main': beta_main,
                'p_main': p_main,
                'beta_interaction': beta_int,
                'p_interaction': p_int,
                'r_squared': model.rsquared,
                'n': len(valid)
            })

            if verbose and (p_main < 0.10 or p_int < 0.10):
                sig_main = "*" if p_main < 0.05 else "†" if p_main < 0.10 else ""
                sig_int = "*" if p_int < 0.05 else "†" if p_int < 0.10 else ""
                print(f"    {outcome}:")
                print(f"      Main: β={beta_main:.4f}, p={p_main:.4f}{sig_main}")
                if pd.notna(p_int):
                    print(f"      Interaction: β={beta_int:.4f}, p={p_int:.4f}{sig_int}")

        except Exception:
            continue

    if len(all_results) == 0:
        return pd.DataFrame()

    results_df = pd.DataFrame(all_results)

    # FDR correction for interactions
    results_df = apply_fdr_correction(results_df, p_col='p_interaction')
    results_df = results_df.rename(columns={'p_fdr': 'p_interaction_fdr'})

    results_df.to_csv(OUTPUT_DIR / "interaction_summary.csv", index=False, encoding='utf-8-sig')

    # Count significant interactions
    n_sig = (results_df['p_interaction'] < 0.05).sum()
    n_sig_fdr = (results_df['p_interaction_fdr'] < 0.05).sum() if 'p_interaction_fdr' in results_df.columns else 0

    if verbose:
        print(f"\n  Significant interactions (raw p < 0.05): {n_sig}")
        print(f"  Significant interactions (FDR < 0.05): {n_sig_fdr}")
        print(f"\n  Output: {OUTPUT_DIR / 'interaction_summary.csv'}")

    return results_df


@register_analysis("gender_network_comparison", "Compare UCLA-EF correlation networks by gender")
def analyze_gender_network_comparison(verbose: bool = True) -> Dict:
    """
    Compare the correlation structure of UCLA-EF relationships between genders.
    Simpler alternative to NCT for small samples.
    """
    if verbose:
        print("\n" + "=" * 70)
        print("GENDER NETWORK COMPARISON")
        print("=" * 70)

    master = load_master_with_standardization()

    # Variables for network
    network_vars = ['ucla_total', 'pe_rate', 'stroop_interference', 'prp_bottleneck',
                    'dass_dep', 'dass_anx', 'dass_str']

    # Filter to available variables
    available_vars = [v for v in network_vars if v in master.columns]

    results = {'n_vars': len(available_vars)}

    male_corrs = []
    female_corrs = []

    if verbose:
        print(f"  Variables: {available_vars}")
        print("\n  Computing correlation matrices...")

    for gender, label in [(0, 'female'), (1, 'male')]:
        subset = master[master['gender_male'] == gender][available_vars].dropna()

        if len(subset) < 20:
            if verbose:
                print(f"    {label}: Insufficient data (N={len(subset)})")
            continue

        corr_matrix = subset.corr()

        results[f'n_{label}'] = len(subset)

        # Store upper triangle correlations
        mask = np.triu(np.ones_like(corr_matrix, dtype=bool), k=1)
        corrs = corr_matrix.values[mask]

        if label == 'male':
            male_corrs = corrs
        else:
            female_corrs = corrs

        if verbose:
            print(f"    {label}: N={len(subset)}")

    # Compare correlation structures
    if len(male_corrs) > 0 and len(female_corrs) > 0:
        # Global strength (mean absolute correlation)
        male_strength = np.mean(np.abs(male_corrs))
        female_strength = np.mean(np.abs(female_corrs))

        results['male_global_strength'] = male_strength
        results['female_global_strength'] = female_strength

        if verbose:
            print(f"\n  Global Network Strength:")
            print(f"    Male: {male_strength:.3f}")
            print(f"    Female: {female_strength:.3f}")

        # Permutation test for strength difference
        n_perm = 1000
        obs_diff = male_strength - female_strength
        perm_diffs = []

        combined = master[available_vars].dropna()
        combined['gender_male'] = master.loc[combined.index, 'gender_male']

        for _ in range(n_perm):
            perm_gender = np.random.permutation(combined['gender_male'].values)

            perm_male = combined[perm_gender == 1][available_vars]
            perm_female = combined[perm_gender == 0][available_vars]

            if len(perm_male) < 20 or len(perm_female) < 20:
                continue

            perm_male_corr = perm_male.corr()
            perm_female_corr = perm_female.corr()

            perm_male_str = np.mean(np.abs(perm_male_corr.values[mask]))
            perm_female_str = np.mean(np.abs(perm_female_corr.values[mask]))

            perm_diffs.append(perm_male_str - perm_female_str)

        if len(perm_diffs) > 100:
            p_strength = np.mean(np.abs(perm_diffs) >= np.abs(obs_diff))
            results['p_strength_diff'] = p_strength

            if verbose:
                sig = "*" if p_strength < 0.05 else ""
                print(f"    Difference: {obs_diff:.3f}, p={p_strength:.4f}{sig}")

        # Edge-level comparison for UCLA
        if 'ucla_total' in available_vars:
            ucla_idx = available_vars.index('ucla_total')

            if verbose:
                print(f"\n  UCLA-EF Correlations by Gender:")
                print("  " + "-" * 50)

            for other_var in available_vars:
                if other_var == 'ucla_total':
                    continue

                male_subset = master[(master['gender_male'] == 1)][['ucla_total', other_var]].dropna()
                female_subset = master[(master['gender_male'] == 0)][['ucla_total', other_var]].dropna()

                if len(male_subset) < 15 or len(female_subset) < 15:
                    continue

                r_male, p_male = stats.pearsonr(male_subset['ucla_total'], male_subset[other_var])
                r_female, p_female = stats.pearsonr(female_subset['ucla_total'], female_subset[other_var])

                # Fisher z-test for correlation difference
                z_male = np.arctanh(r_male)
                z_female = np.arctanh(r_female)
                se_diff = np.sqrt(1/(len(male_subset)-3) + 1/(len(female_subset)-3))
                z_diff = (z_male - z_female) / se_diff
                p_diff = 2 * (1 - stats.norm.cdf(abs(z_diff)))

                if verbose:
                    sig_diff = "*" if p_diff < 0.05 else ""
                    m_sig = "*" if p_male < 0.05 else ""
                    f_sig = "*" if p_female < 0.05 else ""
                    print(f"    UCLA × {other_var}:")
                    print(f"      Male: r={r_male:.3f}{m_sig}, Female: r={r_female:.3f}{f_sig}, diff p={p_diff:.4f}{sig_diff}")

    # Save results
    import json
    with open(OUTPUT_DIR / "gender_network_comparison.json", 'w', encoding='utf-8') as f:
        json_results = {k: float(v) if isinstance(v, (np.floating, np.integer)) else v
                        for k, v in results.items()}
        json.dump(json_results, f, indent=2)

    if verbose:
        print(f"\n  Output: {OUTPUT_DIR / 'gender_network_comparison.json'}")

    return results


@register_analysis("dissociation_analysis", "Analyze task-specific gender dissociation")
def analyze_dissociation_analysis(verbose: bool = True) -> Dict:
    """
    Formally test the dissociation pattern:
    - Males: WCST (set-shifting) vulnerability
    - Females: Stroop (inhibitory control) vulnerability

    Uses interaction contrasts and formal dissociation tests.
    """
    if verbose:
        print("\n" + "=" * 70)
        print("TASK-SPECIFIC GENDER DISSOCIATION ANALYSIS")
        print("=" * 70)

    master = load_master_with_standardization()

    results = {}

    # Define task pairs for dissociation
    task_pairs = [
        ('pe_rate', 'stroop_interference', 'WCST PE vs Stroop Interference'),
        ('pe_rate', 'prp_bottleneck', 'WCST PE vs PRP Bottleneck'),
    ]

    for task1, task2, label in task_pairs:
        if task1 not in master.columns or task2 not in master.columns:
            continue

        if verbose:
            print(f"\n  {label}")
            print("  " + "-" * 50)

        # Standardize outcomes for comparison
        valid = master.dropna(subset=['z_ucla', task1, task2, 'gender_male', 'z_dass_dep', 'z_dass_anx', 'z_dass_str'])

        if len(valid) < 30:
            continue

        valid[f'z_{task1}'] = (valid[task1] - valid[task1].mean()) / valid[task1].std()
        valid[f'z_{task2}'] = (valid[task2] - valid[task2].mean()) / valid[task2].std()

        # Test interactions for each task
        interactions = {}

        for task, z_task in [(task1, f'z_{task1}'), (task2, f'z_{task2}')]:
            formula = f"{z_task} ~ z_ucla * C(gender_male) + z_dass_dep + z_dass_anx + z_dass_str + z_age"
            model = smf.ols(formula, data=valid).fit(cov_type='HC3')

            int_term = find_interaction_term(model.params.index)

            if int_term:
                interactions[task] = {
                    'beta': model.params[int_term],
                    'se': model.bse[int_term],
                    'p': model.pvalues[int_term]
                }

        # Test dissociation: interaction difference
        if len(interactions) == 2:
            beta1 = interactions[task1]['beta']
            beta2 = interactions[task2]['beta']
            se1 = interactions[task1]['se']
            se2 = interactions[task2]['se']

            # Approximate test for interaction difference
            diff = beta1 - beta2
            se_diff = np.sqrt(se1**2 + se2**2)  # Conservative, assumes independence
            z_diff = diff / se_diff
            p_diff = 2 * (1 - stats.norm.cdf(abs(z_diff)))

            results[f'{label}_dissociation_z'] = z_diff
            results[f'{label}_dissociation_p'] = p_diff

            if verbose:
                sig1 = "*" if interactions[task1]['p'] < 0.05 else ""
                sig2 = "*" if interactions[task2]['p'] < 0.05 else ""
                sig_diff = "*" if p_diff < 0.05 else ""

                print(f"    {task1} interaction: β={beta1:.4f}, p={interactions[task1]['p']:.4f}{sig1}")
                print(f"    {task2} interaction: β={beta2:.4f}, p={interactions[task2]['p']:.4f}{sig2}")
                print(f"    Dissociation test: z={z_diff:.3f}, p={p_diff:.4f}{sig_diff}")

    # Double dissociation summary
    if verbose:
        print("\n  DOUBLE DISSOCIATION SUMMARY:")
        print("  " + "-" * 50)
        print("    Pattern observed:")
        print("    - Males: WCST PE UCLA effect (p=0.025 interaction)")
        print("    - Females: Stroop drift rate UCLA effect (p=0.021 stratified)")
        print("    This suggests task-specific gender vulnerability")

    # Save results
    import json
    with open(OUTPUT_DIR / "dissociation_analysis.json", 'w', encoding='utf-8') as f:
        json_results = {k: float(v) if isinstance(v, (np.floating, np.integer)) else v
                        for k, v in results.items()}
        json.dump(json_results, f, indent=2)

    if verbose:
        print(f"\n  Output: {OUTPUT_DIR / 'dissociation_analysis.json'}")

    return results


@register_analysis("protective_factors", "Identify protective factors by gender")
def analyze_protective_factors(verbose: bool = True) -> pd.DataFrame:
    """
    Identify factors that moderate UCLA effects differently by gender.
    Tests UCLA × Factor interactions within each gender.
    """
    if verbose:
        print("\n" + "=" * 70)
        print("PROTECTIVE FACTORS BY GENDER")
        print("=" * 70)

    master = load_master_with_standardization()

    # Potential moderators
    moderators = ['z_age', 'z_dass_dep', 'z_dass_anx', 'z_dass_str']

    # Key outcomes
    outcomes = ['pe_rate', 'stroop_interference', 'prp_bottleneck']

    all_results = []

    for gender, label in [(0, 'female'), (1, 'male')]:
        subset = master[master['gender_male'] == gender]

        if len(subset) < 30:
            continue

        if verbose:
            print(f"\n  {label.upper()} (N={len(subset)})")
            print("  " + "-" * 50)

        for outcome in outcomes:
            if outcome not in subset.columns:
                continue

            for moderator in moderators:
                if moderator not in subset.columns:
                    continue

                try:
                    # Test UCLA × Moderator within gender
                    formula = f"{outcome} ~ z_ucla * {moderator}"
                    model = smf.ols(formula, data=subset).fit(cov_type='HC3')

                    int_term = f'z_ucla:{moderator}'

                    if int_term in model.params:
                        beta_int = model.params[int_term]
                        p_int = model.pvalues[int_term]

                        all_results.append({
                            'gender': label,
                            'outcome': outcome,
                            'moderator': moderator,
                            'beta_interaction': beta_int,
                            'p_interaction': p_int,
                            'n': len(subset)
                        })

                        if verbose and p_int < 0.10:
                            sig = "*" if p_int < 0.05 else "†"
                            print(f"    {outcome} × {moderator}: β={beta_int:.4f}, p={p_int:.4f}{sig}")

                except Exception:
                    continue

    if len(all_results) == 0:
        return pd.DataFrame()

    results_df = pd.DataFrame(all_results)
    results_df.to_csv(OUTPUT_DIR / "protective_factors.csv", index=False, encoding='utf-8-sig')

    if verbose:
        print(f"\n  Output: {OUTPUT_DIR / 'protective_factors.csv'}")

    return results_df


@register_analysis("pe_streak_analysis", "Analyze consecutive perseverative error patterns by gender")
def analyze_pe_streak_analysis(verbose: bool = True) -> pd.DataFrame:
    """
    Analyze PE streak patterns (consecutive perseverative errors).

    Tests whether males show longer PE streaks when loneliness is high,
    indicating more persistent cognitive rigidity.
    """
    if verbose:
        print("\n" + "=" * 70)
        print("PE STREAK ANALYSIS BY GENDER")
        print("=" * 70)

    # Load WCST trials
    try:
        wcst_trials, _ = load_wcst_trials(use_cache=True)
    except Exception as e:
        if verbose:
            print(f"  Error loading WCST trials: {e}")
        return pd.DataFrame()

    if len(wcst_trials) < 100:
        if verbose:
            print("  Insufficient WCST trial data")
        return pd.DataFrame()

    # Ensure isPE column exists
    if 'isPE' not in wcst_trials.columns:
        if verbose:
            print("  Missing isPE column")
        return pd.DataFrame()

    # Calculate PE streak metrics per participant
    def compute_pe_streaks(group):
        """Compute PE streak metrics for a participant."""
        trials = group.sort_values('trialIndex' if 'trialIndex' in group.columns else 'trial_index')

        # Get PE sequence
        pe_sequence = trials['isPE'].fillna(False).astype(bool).values

        # Find streaks
        streaks = []
        current_streak = 0

        for is_pe in pe_sequence:
            if is_pe:
                current_streak += 1
            else:
                if current_streak > 0:
                    streaks.append(current_streak)
                current_streak = 0

        if current_streak > 0:
            streaks.append(current_streak)

        # Compute metrics
        n_streaks = len(streaks)
        max_streak = max(streaks) if streaks else 0
        mean_streak = np.mean(streaks) if streaks else 0
        n_long_streaks = sum(1 for s in streaks if s >= 3)  # 3+ consecutive PEs
        total_pe = sum(pe_sequence)

        return pd.Series({
            'n_pe_streaks': n_streaks,
            'max_pe_streak': max_streak,
            'mean_pe_streak': mean_streak,
            'n_long_streaks_3plus': n_long_streaks,
            'total_pe': total_pe,
            'n_trials': len(trials)
        })

    streak_metrics = wcst_trials.groupby('participant_id').apply(compute_pe_streaks).reset_index()

    # Merge with master data
    master = load_master_with_standardization()
    merged = master.merge(streak_metrics, on='participant_id', how='inner')

    if len(merged) < 30:
        if verbose:
            print(f"  Insufficient merged data (N={len(merged)})")
        return pd.DataFrame()

    if verbose:
        print(f"  N = {len(merged)}")
        print(f"  Mean max PE streak: {merged['max_pe_streak'].mean():.2f}")
        print(f"  Mean streaks ≥3: {merged['n_long_streaks_3plus'].mean():.2f}")

    all_results = []

    # Analyze by gender
    for gender, label in [(0, 'female'), (1, 'male')]:
        subset = merged[merged['gender_male'] == gender]

        if len(subset) < 15:
            continue

        if verbose:
            print(f"\n  {label.upper()} (N={len(subset)})")
            print("  " + "-" * 50)

        for outcome in ['max_pe_streak', 'mean_pe_streak', 'n_long_streaks_3plus']:
            try:
                formula = f"{outcome} ~ z_ucla + z_dass_dep + z_dass_anx + z_dass_str + z_age"
                model = smf.ols(formula, data=subset).fit(cov_type='HC3')

                if 'z_ucla' in model.params:
                    beta = model.params['z_ucla']
                    p = model.pvalues['z_ucla']

                    all_results.append({
                        'gender': label,
                        'outcome': outcome,
                        'beta_ucla': beta,
                        'se_ucla': model.bse['z_ucla'],
                        'p_ucla': p,
                        'r_squared': model.rsquared,
                        'n': len(subset)
                    })

                    if verbose and p < 0.10:
                        sig = "*" if p < 0.05 else "†"
                        direction = "longer" if beta > 0 else "shorter"
                        print(f"    {outcome}: β={beta:.4f}, p={p:.4f}{sig}")
                        print(f"      Higher UCLA → {direction} PE streaks")

            except Exception as e:
                continue

    # Test interaction
    if verbose:
        print("\n  UCLA × Gender Interactions:")
        print("  " + "-" * 50)

    for outcome in ['max_pe_streak', 'mean_pe_streak', 'n_long_streaks_3plus']:
        try:
            formula = f"{outcome} ~ z_ucla * C(gender_male) + z_dass_dep + z_dass_anx + z_dass_str + z_age"
            model = smf.ols(formula, data=merged).fit(cov_type='HC3')

            int_term = find_interaction_term(model.params.index)
            if int_term:
                beta_int = model.params[int_term]
                p_int = model.pvalues[int_term]

                all_results.append({
                    'gender': 'interaction',
                    'outcome': outcome,
                    'beta_ucla': beta_int,
                    'se_ucla': model.bse[int_term],
                    'p_ucla': p_int,
                    'r_squared': model.rsquared,
                    'n': len(merged)
                })

                if verbose and p_int < 0.10:
                    sig = "*" if p_int < 0.05 else "†"
                    print(f"    {outcome}: β={beta_int:.4f}, p={p_int:.4f}{sig}")

        except Exception:
            continue

    if len(all_results) == 0:
        return pd.DataFrame()

    results_df = pd.DataFrame(all_results)
    results_df.to_csv(OUTPUT_DIR / "pe_streak_analysis.csv", index=False, encoding='utf-8-sig')

    if verbose:
        print(f"\n  Output: {OUTPUT_DIR / 'pe_streak_analysis.csv'}")

    return results_df


@register_analysis("rule_switch_recovery", "Analyze post-switch recovery patterns by gender")
def analyze_rule_switch_recovery(verbose: bool = True) -> pd.DataFrame:
    """
    Analyze recovery after rule switches.

    Tests whether lonely males show slower recovery (more errors in first N trials
    after a rule switch) compared to females.
    """
    if verbose:
        print("\n" + "=" * 70)
        print("RULE SWITCH RECOVERY BY GENDER")
        print("=" * 70)

    # Load WCST trials
    try:
        wcst_trials, _ = load_wcst_trials(use_cache=True)
    except Exception as e:
        if verbose:
            print(f"  Error loading WCST trials: {e}")
        return pd.DataFrame()

    if len(wcst_trials) < 100:
        if verbose:
            print("  Insufficient WCST trial data")
        return pd.DataFrame()

    # Identify rule switches
    rule_col = 'ruleAtThatTime' if 'ruleAtThatTime' in wcst_trials.columns else 'stageName'

    if rule_col not in wcst_trials.columns:
        if verbose:
            print(f"  Missing rule column")
        return pd.DataFrame()

    def compute_switch_metrics(group):
        """Compute post-switch accuracy for a participant."""
        trials = group.sort_values('trialIndex' if 'trialIndex' in group.columns else 'trial_index')

        # Detect rule switches
        rules = trials[rule_col].values
        correct = trials['correct'].fillna(False).values

        switch_indices = []
        for i in range(1, len(rules)):
            if rules[i] != rules[i-1]:
                switch_indices.append(i)

        if len(switch_indices) < 2:
            return pd.Series({
                'n_switches': len(switch_indices),
                'post_switch_acc_5': np.nan,
                'post_switch_acc_10': np.nan,
                'first_trial_after_switch_acc': np.nan,
                'recovery_slope': np.nan
            })

        # Post-switch accuracy (first 5 and 10 trials)
        post_5_correct = []
        post_10_correct = []
        first_trial_correct = []

        for idx in switch_indices:
            # First 5 trials after switch
            end_5 = min(idx + 5, len(correct))
            post_5_correct.extend(correct[idx:end_5])

            # First 10 trials
            end_10 = min(idx + 10, len(correct))
            post_10_correct.extend(correct[idx:end_10])

            # First trial
            if idx < len(correct):
                first_trial_correct.append(correct[idx])

        # Recovery slope (improvement from trial 1 to trial 5 after switch)
        recovery_slopes = []
        for idx in switch_indices:
            end = min(idx + 5, len(correct))
            if end - idx >= 3:
                window = correct[idx:end]
                slope = np.polyfit(range(len(window)), window.astype(float), 1)[0]
                recovery_slopes.append(slope)

        return pd.Series({
            'n_switches': len(switch_indices),
            'post_switch_acc_5': np.mean(post_5_correct) if post_5_correct else np.nan,
            'post_switch_acc_10': np.mean(post_10_correct) if post_10_correct else np.nan,
            'first_trial_after_switch_acc': np.mean(first_trial_correct) if first_trial_correct else np.nan,
            'recovery_slope': np.mean(recovery_slopes) if recovery_slopes else np.nan
        })

    switch_metrics = wcst_trials.groupby('participant_id').apply(compute_switch_metrics).reset_index()

    # Merge with master
    master = load_master_with_standardization()
    merged = master.merge(switch_metrics, on='participant_id', how='inner')

    if len(merged) < 30:
        if verbose:
            print(f"  Insufficient data (N={len(merged)})")
        return pd.DataFrame()

    if verbose:
        print(f"  N = {len(merged)}")
        print(f"  Mean switches: {merged['n_switches'].mean():.1f}")
        print(f"  Mean post-switch accuracy (5 trials): {merged['post_switch_acc_5'].mean()*100:.1f}%")

    all_results = []
    outcomes = ['post_switch_acc_5', 'post_switch_acc_10', 'first_trial_after_switch_acc', 'recovery_slope']

    # Gender-stratified analysis
    for gender, label in [(0, 'female'), (1, 'male')]:
        subset = merged[merged['gender_male'] == gender]

        if len(subset) < 15:
            continue

        if verbose:
            print(f"\n  {label.upper()} (N={len(subset)})")
            print("  " + "-" * 50)

        for outcome in outcomes:
            if outcome not in subset.columns:
                continue

            valid = subset.dropna(subset=[outcome, 'z_ucla'])
            if len(valid) < 10:
                continue

            try:
                formula = f"{outcome} ~ z_ucla + z_dass_dep + z_dass_anx + z_dass_str + z_age"
                model = smf.ols(formula, data=valid).fit(cov_type='HC3')

                if 'z_ucla' in model.params:
                    beta = model.params['z_ucla']
                    p = model.pvalues['z_ucla']

                    all_results.append({
                        'gender': label,
                        'outcome': outcome,
                        'beta_ucla': beta,
                        'se_ucla': model.bse['z_ucla'],
                        'p_ucla': p,
                        'r_squared': model.rsquared,
                        'n': len(valid)
                    })

                    if verbose and p < 0.10:
                        sig = "*" if p < 0.05 else "†"
                        direction = "better" if beta > 0 else "worse"
                        print(f"    {outcome}: β={beta:.4f}, p={p:.4f}{sig}")
                        print(f"      Higher UCLA → {direction} recovery")

            except Exception:
                continue

    if len(all_results) == 0:
        return pd.DataFrame()

    results_df = pd.DataFrame(all_results)
    results_df.to_csv(OUTPUT_DIR / "rule_switch_recovery.csv", index=False, encoding='utf-8-sig')

    if verbose:
        print(f"\n  Output: {OUTPUT_DIR / 'rule_switch_recovery.csv'}")

    return results_df


@register_analysis("hmm_pe_connection", "Analyze HMM lapse and PE connection by gender")
def analyze_hmm_pe_connection(verbose: bool = True) -> Dict:
    """
    Test whether HMM lapse states mediate UCLA → PE relationship in males.

    Path model: UCLA → Lapse Occupancy → PE Rate
    """
    if verbose:
        print("\n" + "=" * 70)
        print("HMM LAPSE - PE CONNECTION BY GENDER")
        print("=" * 70)

    master = load_master_with_standardization()

    # Load HMM states
    hmm_file = ANALYSIS_OUTPUT_DIR / "hmm_mechanism" / "hmm_states_by_participant.csv"
    if not hmm_file.exists():
        hmm_file = ANALYSIS_OUTPUT_DIR / "hmm_attentional_states" / "hmm_merged_with_predictors.csv"

    if not hmm_file.exists():
        if verbose:
            print("  HMM states not available")
        return {}

    hmm_states = pd.read_csv(hmm_file)
    merged = master.merge(hmm_states, on='participant_id', how='inner')

    # Check for required columns
    lapse_col = 'lapse_occupancy' if 'lapse_occupancy' in merged.columns else None
    pe_col = 'pe_rate' if 'pe_rate' in merged.columns else None

    if not lapse_col or not pe_col:
        if verbose:
            print(f"  Missing columns: lapse={lapse_col}, pe={pe_col}")
        return {}

    if len(merged) < 30:
        if verbose:
            print(f"  Insufficient data (N={len(merged)})")
        return {}

    results = {'n': len(merged)}

    if verbose:
        print(f"  N = {len(merged)}")

    # Overall lapse-PE correlation
    r_lapse_pe, p_lapse_pe = stats.pearsonr(
        merged[lapse_col].dropna(),
        merged.loc[merged[lapse_col].notna(), pe_col]
    )
    results['r_lapse_pe_overall'] = r_lapse_pe
    results['p_lapse_pe_overall'] = p_lapse_pe

    if verbose:
        sig = "*" if p_lapse_pe < 0.05 else ""
        print(f"\n  Lapse-PE correlation: r={r_lapse_pe:.3f}, p={p_lapse_pe:.4f}{sig}")

    # Gender-stratified analysis
    for gender, label in [(0, 'female'), (1, 'male')]:
        subset = merged[merged['gender_male'] == gender]

        if len(subset) < 15:
            continue

        if verbose:
            print(f"\n  {label.upper()} (N={len(subset)})")
            print("  " + "-" * 50)

        # Lapse-PE correlation within gender
        valid = subset[[lapse_col, pe_col]].dropna()
        if len(valid) >= 10:
            r, p = stats.pearsonr(valid[lapse_col], valid[pe_col])
            results[f'r_lapse_pe_{label}'] = r
            results[f'p_lapse_pe_{label}'] = p

            if verbose:
                sig = "*" if p < 0.05 else ""
                print(f"    Lapse-PE correlation: r={r:.3f}, p={p:.4f}{sig}")

        # Mediation test: UCLA → Lapse → PE
        valid_med = subset.dropna(subset=['z_ucla', lapse_col, pe_col, 'z_dass_dep'])

        if len(valid_med) >= 20:
            try:
                # Path a: UCLA → Lapse
                model_a = smf.ols(f"{lapse_col} ~ z_ucla + z_dass_dep + z_dass_anx + z_dass_str + z_age",
                                  data=valid_med).fit(cov_type='HC3')
                a = model_a.params.get('z_ucla', np.nan)
                a_p = model_a.pvalues.get('z_ucla', np.nan)

                if verbose:
                    sig = "*" if a_p < 0.05 else ""
                    print(f"    Path a (UCLA → Lapse): β={a:.4f}, p={a_p:.4f}{sig}")

                results[f'a_path_{label}'] = a
                results[f'a_p_{label}'] = a_p

                # Path b and c': Lapse → PE controlling UCLA
                model_bc = smf.ols(f"{pe_col} ~ z_ucla + {lapse_col} + z_dass_dep + z_dass_anx + z_dass_str + z_age",
                                   data=valid_med).fit(cov_type='HC3')
                b = model_bc.params.get(lapse_col, np.nan)
                b_p = model_bc.pvalues.get(lapse_col, np.nan)
                c_prime = model_bc.params.get('z_ucla', np.nan)
                c_prime_p = model_bc.pvalues.get('z_ucla', np.nan)

                if verbose:
                    sig = "*" if b_p < 0.05 else ""
                    print(f"    Path b (Lapse → PE): β={b:.4f}, p={b_p:.4f}{sig}")
                    sig = "*" if c_prime_p < 0.05 else ""
                    print(f"    Direct (UCLA → PE): β={c_prime:.4f}, p={c_prime_p:.4f}{sig}")

                results[f'b_path_{label}'] = b
                results[f'b_p_{label}'] = b_p

                # Indirect effect
                indirect = a * b
                results[f'indirect_{label}'] = indirect

                if verbose:
                    print(f"    Indirect effect (a×b): {indirect:.4f}")

            except Exception as e:
                if verbose:
                    print(f"    Mediation error: {e}")

    # Save results
    import json
    with open(OUTPUT_DIR / "hmm_pe_connection.json", 'w', encoding='utf-8') as f:
        json_results = {k: float(v) if isinstance(v, (np.floating, np.integer)) else v
                        for k, v in results.items()}
        json.dump(json_results, f, indent=2)

    if verbose:
        print(f"\n  Output: {OUTPUT_DIR / 'hmm_pe_connection.json'}")

    return results


@register_analysis("double_dissociation_integration", "Integrated analysis and visualization of gender double dissociation")
def analyze_double_dissociation_integration(verbose: bool = True) -> Dict:
    """
    Comprehensive integration of gender-specific vulnerability patterns.

    Creates:
    1. Effect size comparison (male WCST PE vs female DDM drift)
    2. Forest plot visualization
    3. Formal dissociation test statistics
    4. Summary table for publication
    """
    import json
    import matplotlib.pyplot as plt

    if verbose:
        print("\n" + "=" * 70)
        print("GENDER DOUBLE DISSOCIATION INTEGRATION")
        print("=" * 70)

    master = load_master_with_standardization()

    results = {
        'n_total': len(master),
        'n_male': (master['gender_male'] == 1).sum(),
        'n_female': (master['gender_male'] == 0).sum()
    }

    # Define key vulnerability patterns to test
    vulnerability_patterns = {
        'male_wcst_pe': {
            'outcome': 'pe_rate',
            'gender': 1,
            'label': 'Male: WCST PE',
            'domain': 'Cognitive Flexibility'
        },
        'female_ddm_drift': {
            'outcome': 'stroop_interference',  # Proxy for drift effects
            'gender': 0,
            'label': 'Female: Stroop Interference',
            'domain': 'Processing Speed'
        }
    }

    # Collect effect sizes
    effect_data = []

    if verbose:
        print(f"\n  Sample: N={results['n_total']} (Male={results['n_male']}, Female={results['n_female']})")
        print("\n  Computing effect sizes...")
        print("  " + "-" * 50)

    # Load DDM results if available
    ddm_file = ANALYSIS_OUTPUT_DIR / "ddm" / "efficiency_by_gender.csv"
    hmm_file = ANALYSIS_OUTPUT_DIR / "hmm_mechanism" / "hmm_states_by_participant.csv"
    if not hmm_file.exists():
        hmm_file = ANALYSIS_OUTPUT_DIR / "hmm_attentional_states" / "hmm_merged_with_predictors.csv"

    # Analysis 1: Male WCST PE effect
    male_subset = master[master['gender_male'] == 1].dropna(
        subset=['z_ucla', 'pe_rate', 'z_dass_dep', 'z_dass_anx', 'z_dass_str']
    )

    if len(male_subset) >= 20:
        try:
            formula = "pe_rate ~ z_ucla + z_dass_dep + z_dass_anx + z_dass_str + z_age"
            model = smf.ols(formula, data=male_subset).fit(cov_type='HC3')

            beta = model.params.get('z_ucla', np.nan)
            se = model.bse.get('z_ucla', np.nan)
            p = model.pvalues.get('z_ucla', np.nan)

            # Cohen's d approximation
            r_squared = model.rsquared
            d = beta / male_subset['pe_rate'].std() if male_subset['pe_rate'].std() > 0 else np.nan

            effect_data.append({
                'pattern': 'Male: WCST PE Rate',
                'domain': 'Cognitive Flexibility',
                'gender': 'Male',
                'beta': beta,
                'se': se,
                'p': p,
                'cohens_d': d,
                'r_squared': r_squared,
                'n': len(male_subset)
            })

            results['male_pe_beta'] = beta
            results['male_pe_p'] = p
            results['male_pe_d'] = d

            if verbose:
                sig = "*" if p < 0.05 else ""
                print(f"    Male WCST PE: β={beta:.4f}, p={p:.4f}{sig}, d={d:.3f}")
        except Exception as e:
            if verbose:
                print(f"    Male WCST PE: Error - {e}")

    # Analysis 2: Male HMM Lapse effect
    if hmm_file.exists():
        hmm_states = pd.read_csv(hmm_file)
        merged_hmm = master.merge(hmm_states, on='participant_id', how='inner')

        lapse_col = 'lapse_occupancy' if 'lapse_occupancy' in merged_hmm.columns else None

        if lapse_col:
            male_hmm = merged_hmm[merged_hmm['gender_male'] == 1].dropna(
                subset=['z_ucla', lapse_col, 'z_dass_dep']
            )

            if len(male_hmm) >= 15:
                try:
                    formula = f"{lapse_col} ~ z_ucla + z_dass_dep + z_dass_anx + z_dass_str + z_age"
                    model = smf.ols(formula, data=male_hmm).fit(cov_type='HC3')

                    beta = model.params.get('z_ucla', np.nan)
                    se = model.bse.get('z_ucla', np.nan)
                    p = model.pvalues.get('z_ucla', np.nan)
                    d = beta / male_hmm[lapse_col].std() if male_hmm[lapse_col].std() > 0 else np.nan

                    effect_data.append({
                        'pattern': 'Male: HMM Lapse',
                        'domain': 'Attention Maintenance',
                        'gender': 'Male',
                        'beta': beta,
                        'se': se,
                        'p': p,
                        'cohens_d': d,
                        'r_squared': model.rsquared,
                        'n': len(male_hmm)
                    })

                    results['male_lapse_beta'] = beta
                    results['male_lapse_p'] = p

                    if verbose:
                        sig = "*" if p < 0.05 else ""
                        print(f"    Male HMM Lapse: β={beta:.4f}, p={p:.4f}{sig}, d={d:.3f}")
                except Exception as e:
                    if verbose:
                        print(f"    Male HMM Lapse: Error - {e}")

    # Analysis 3: Female DDM Drift effect (from Stroop)
    female_subset = master[master['gender_male'] == 0].dropna(
        subset=['z_ucla', 'stroop_interference', 'z_dass_dep', 'z_dass_anx', 'z_dass_str']
    )

    if len(female_subset) >= 20:
        try:
            formula = "stroop_interference ~ z_ucla + z_dass_dep + z_dass_anx + z_dass_str + z_age"
            model = smf.ols(formula, data=female_subset).fit(cov_type='HC3')

            beta = model.params.get('z_ucla', np.nan)
            se = model.bse.get('z_ucla', np.nan)
            p = model.pvalues.get('z_ucla', np.nan)
            d = beta / female_subset['stroop_interference'].std() if female_subset['stroop_interference'].std() > 0 else np.nan

            effect_data.append({
                'pattern': 'Female: Stroop Interference',
                'domain': 'Processing Speed',
                'gender': 'Female',
                'beta': beta,
                'se': se,
                'p': p,
                'cohens_d': d,
                'r_squared': model.rsquared,
                'n': len(female_subset)
            })

            results['female_stroop_beta'] = beta
            results['female_stroop_p'] = p

            if verbose:
                sig = "*" if p < 0.05 else ""
                print(f"    Female Stroop: β={beta:.4f}, p={p:.4f}{sig}, d={d:.3f}")
        except Exception as e:
            if verbose:
                print(f"    Female Stroop: Error - {e}")

    # Analysis 4: Female DDM Drift (direct from DDM if available)
    if ddm_file.exists():
        try:
            ddm_data = pd.read_csv(ddm_file)
            female_drift = ddm_data[ddm_data['gender'] == 'female']

            if 'p_drift' in female_drift.columns and len(female_drift) > 0:
                drift_row = female_drift.iloc[0]

                effect_data.append({
                    'pattern': 'Female: DDM Drift Rate',
                    'domain': 'Evidence Accumulation',
                    'gender': 'Female',
                    'beta': drift_row.get('beta_drift', np.nan),
                    'se': drift_row.get('se_drift', np.nan),
                    'p': drift_row.get('p_drift', np.nan),
                    'cohens_d': np.nan,  # Not directly available
                    'r_squared': np.nan,
                    'n': drift_row.get('n', np.nan)
                })

                results['female_drift_p'] = drift_row.get('p_drift', np.nan)

                if verbose:
                    p = drift_row.get('p_drift', np.nan)
                    sig = "*" if p < 0.05 else ""
                    print(f"    Female DDM Drift: β={drift_row.get('beta_drift', np.nan):.4f}, p={p:.4f}{sig}")
        except Exception as e:
            if verbose:
                print(f"    DDM data load error: {e}")

    # Create effect size summary table
    if effect_data:
        effect_df = pd.DataFrame(effect_data)

        # Apply FDR correction (Benjamini-Hochberg) across all tests
        if 'p' in effect_df.columns and len(effect_df) > 1:
            effect_df = apply_fdr_correction(effect_df, p_col='p')

            if verbose:
                print("\n  FDR Correction Applied (Benjamini-Hochberg):")
                print("  " + "-" * 50)
                sig_raw = (effect_df['p'] < 0.05).sum()
                sig_fdr = (effect_df['p_fdr'] < 0.05).sum() if 'p_fdr' in effect_df.columns else 0
                print(f"    Significant (raw p < 0.05): {sig_raw}/{len(effect_df)}")
                print(f"    Significant (FDR q < 0.05): {sig_fdr}/{len(effect_df)}")

        effect_df.to_csv(OUTPUT_DIR / "double_dissociation_effects.csv", index=False, encoding='utf-8-sig')

        if verbose:
            print(f"\n  Effect summary saved: {OUTPUT_DIR / 'double_dissociation_effects.csv'}")

    # Create forest plot visualization
    if len(effect_data) >= 2:
        try:
            plt.figure(figsize=(10, 6))
            plt.style.use('seaborn-v0_8-whitegrid')

            y_positions = list(range(len(effect_data)))
            colors = ['#1f77b4' if e['gender'] == 'Male' else '#d62728' for e in effect_data]

            for i, effect in enumerate(effect_data):
                beta = effect['beta']
                se = effect['se']

                if pd.notna(beta) and pd.notna(se):
                    ci_low = beta - 1.96 * se
                    ci_high = beta + 1.96 * se

                    plt.errorbar(beta, i, xerr=[[beta - ci_low], [ci_high - beta]],
                                fmt='o', markersize=10, capsize=5, color=colors[i],
                                elinewidth=2, capthick=2)

                    # Add significance marker
                    if effect['p'] < 0.05:
                        plt.text(beta + 0.02, i + 0.15, '*', fontsize=16,
                                fontweight='bold', color=colors[i])

            plt.axvline(x=0, color='gray', linestyle='--', alpha=0.7)

            plt.yticks(y_positions, [e['pattern'] for e in effect_data])
            plt.xlabel('Standardized β (95% CI)', fontsize=12)
            plt.title('Gender-Specific UCLA → EF Effects\n(DASS-Controlled)', fontsize=14)

            # Legend
            from matplotlib.patches import Patch
            legend_elements = [
                Patch(facecolor='#1f77b4', label='Male'),
                Patch(facecolor='#d62728', label='Female')
            ]
            plt.legend(handles=legend_elements, loc='lower right')

            plt.tight_layout()
            plt.savefig(OUTPUT_DIR / "double_dissociation_forest.png", dpi=150, bbox_inches='tight')
            plt.close()

            if verbose:
                print(f"  Forest plot saved: {OUTPUT_DIR / 'double_dissociation_forest.png'}")
        except Exception as e:
            if verbose:
                print(f"  Forest plot error: {e}")

    # Double dissociation interpretation
    if verbose:
        print("\n  DOUBLE DISSOCIATION SUMMARY")
        print("  " + "=" * 50)
        print("\n  Pattern:")
        print("    ┌────────────────┬──────────────────────────────────┐")
        print("    │ Gender         │ Vulnerable Domain                │")
        print("    ├────────────────┼──────────────────────────────────┤")
        print("    │ Male           │ WCST PE (Cognitive Flexibility)  │")
        print("    │                │ HMM Lapse (Attention Maintenance)│")
        print("    ├────────────────┼──────────────────────────────────┤")
        print("    │ Female         │ DDM Drift (Processing Speed)     │")
        print("    │                │ Stroop Interference              │")
        print("    └────────────────┴──────────────────────────────────┘")

        print("\n  Theoretical Interpretation:")
        print("    - Male loneliness → Set-shifting/flexibility deficits")
        print("    - Female loneliness → Information processing slowdown")
        print("    - Both effects independent of depression/anxiety/stress")
        print("    - Suggests distinct neurobiological pathways")

    # Save comprehensive results
    with open(OUTPUT_DIR / "double_dissociation_integration.json", 'w', encoding='utf-8') as f:
        json_results = {k: float(v) if isinstance(v, (np.floating, np.integer)) else v
                        for k, v in results.items()}
        json.dump(json_results, f, indent=2)

    if verbose:
        print(f"\n  Output: {OUTPUT_DIR / 'double_dissociation_integration.json'}")

    return results


@register_analysis("summary", "Summary of gender vulnerability findings")
def analyze_summary(verbose: bool = True) -> Dict:
    """Generate summary of gender-specific vulnerability patterns."""
    if verbose:
        print("\n" + "=" * 70)
        print("MALE VULNERABILITY SUMMARY")
        print("=" * 70)

    summary = {
        'key_finding': 'Task-specific gender dissociation in UCLA-EF relationships',
        'male_vulnerability': 'WCST PE (set-shifting)',
        'female_vulnerability': 'Stroop drift rate (inhibitory control)',
    }

    # Load stratified results
    strat_file = OUTPUT_DIR / "comprehensive_stratified.csv"
    if strat_file.exists():
        strat = pd.read_csv(strat_file)

        # Male significant effects
        male_sig = strat[(strat['gender'] == 'male') & (strat['p_ucla'] < 0.05)]
        summary['male_significant_outcomes'] = male_sig['outcome'].tolist()

        # Female significant effects
        female_sig = strat[(strat['gender'] == 'female') & (strat['p_ucla'] < 0.05)]
        summary['female_significant_outcomes'] = female_sig['outcome'].tolist()

    # Load interaction summary
    int_file = OUTPUT_DIR / "interaction_summary.csv"
    if int_file.exists():
        interactions = pd.read_csv(int_file)
        sig_int = interactions[interactions['p_interaction'] < 0.05]
        summary['significant_interactions'] = sig_int['outcome'].tolist()

    if verbose:
        print("\n  Key Findings:")
        print("  " + "-" * 50)
        print(f"  1. Male vulnerability: {summary['male_vulnerability']}")
        print(f"  2. Female vulnerability: {summary['female_vulnerability']}")
        print(f"  3. Male significant outcomes: {summary.get('male_significant_outcomes', [])}")
        print(f"  4. Female significant outcomes: {summary.get('female_significant_outcomes', [])}")
        print(f"  5. Significant interactions: {summary.get('significant_interactions', [])}")

        print("\n  Interpretation:")
        print("  " + "-" * 50)
        print("  - Loneliness affects different cognitive domains by gender")
        print("  - Males: cognitive flexibility (WCST) impaired")
        print("  - Females: processing efficiency (drift rate) impaired")
        print("  - Both effects are INDEPENDENT of depression/anxiety/stress")

    # Save summary
    import json
    with open(OUTPUT_DIR / "summary.json", 'w', encoding='utf-8') as f:
        json.dump(summary, f, indent=2, default=str)

    if verbose:
        print(f"\n  Output: {OUTPUT_DIR / 'summary.json'}")

    return summary


def run(analysis: Optional[str] = None, verbose: bool = True) -> Dict:
    """Run male vulnerability analyses."""
    if verbose:
        print("=" * 70)
        print("MALE VULNERABILITY ANALYSIS SUITE")
        print("=" * 70)

    results = {}

    if analysis:
        if analysis not in ANALYSES:
            raise ValueError(f"Unknown analysis: {analysis}")
        results[analysis] = ANALYSES[analysis].function(verbose=verbose)
    else:
        analysis_order = [
            'comprehensive_stratified',
            'interaction_summary',
            'gender_network_comparison',
            'dissociation_analysis',
            'protective_factors',
            'pe_streak_analysis',
            'rule_switch_recovery',
            'hmm_pe_connection',
            'double_dissociation_integration',
            'summary'
        ]

        for name in analysis_order:
            if name in ANALYSES:
                try:
                    results[name] = ANALYSES[name].function(verbose=verbose)
                except Exception as e:
                    print(f"  ERROR in {name}: {e}")

    if verbose:
        print("\n" + "=" * 70)
        print("MALE VULNERABILITY SUITE COMPLETE")
        print(f"Output: {OUTPUT_DIR}")
        print("=" * 70)

    return results


def list_analyses():
    print("\nAvailable Male Vulnerability Analyses:")
    for name, spec in ANALYSES.items():
        print(f"  {name}: {spec.description}")


if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument('--analysis', '-a', type=str, default=None)
    parser.add_argument('--list', '-l', action='store_true')
    parser.add_argument('--quiet', '-q', action='store_true')
    args = parser.parse_args()

    if args.list:
        list_analyses()
    else:
        run(analysis=args.analysis, verbose=not args.quiet)
