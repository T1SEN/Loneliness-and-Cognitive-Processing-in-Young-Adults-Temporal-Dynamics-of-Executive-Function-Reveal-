
================================================================================
BONFERRONI CORRECTION INTERPRETATION GUIDE
================================================================================

Date: 2024-11-17
Total tests: 149
Original α: 0.05
Bonferroni-corrected α: 0.000336 (≈ 3.36e-04)

================================================================================
WHAT IS BONFERRONI CORRECTION?
================================================================================

Problem:
--------
Conducting multiple statistical tests increases the probability of false
positives (Type I errors). If we run 100 tests at α=0.05, we expect 5
false positives just by chance.

Solution:
---------
Bonferroni correction controls the **family-wise error rate (FWER)** by
dividing the original α by the number of tests:

    α_corrected = α_original / n_tests

This ensures that the probability of making ANY false positive across all
tests is ≤ α_original.

Interpretation:
---------------
After Bonferroni correction, only p-values < 0.000336 are considered
statistically significant. This is a VERY conservative threshold.

================================================================================
FRAMEWORK-SPECIFIC APPLICATIONS
================================================================================

Framework 1: Regression Mixture Modeling
-----------------------------------------
Tests: 120 (3 outcomes × 5 classes × 8 parameters)
Correction: Applied to within-class regression p-values

**Impact:** Most p<0.05 effects will become non-significant after correction.
This does NOT mean effects are absent - it means we cannot claim statistical
significance at the corrected threshold.

**Recommendation:**
- Report both original and Bonferroni-corrected results
- Focus on effect sizes (β coefficients) rather than p-values
- Use Bonferroni for confirmatory claims only
- Consider False Discovery Rate (FDR) as alternative (less conservative)

Framework 2: Normative Modeling
--------------------------------
Tests: 9 (3 outcomes × 3 parameters)
Correction: Applied to deviation regression p-values

**Note:** Framework 2 already excluded due to overfitting, so this is
supplementary information only.

Framework 3: Latent Factor/SEM
-------------------------------
Tests: 0 (CFA failed)
Correction: Not applicable

Framework 4: Bayesian Causal DAG
---------------------------------
Tests: 20 (4 models × ~5 parameters)
Correction: NOT APPLICABLE (Bayesian uses HDI, not p-values)

**Note:** Bayesian inference does not use null hypothesis testing or p-values.
"Significance" is determined by whether 95% HDI excludes zero. This is a
fundamentally different paradigm that does not require FWER correction.

================================================================================
RECOMMENDATIONS FOR MANUSCRIPT
================================================================================

1. **Be Transparent:**
   Report both original (p<0.05) and Bonferroni-corrected results in tables.

2. **Use Bonferroni for Confirmatory Claims:**
   Main hypotheses should survive Bonferroni correction.

3. **Acknowledge Conservativeness:**
   Bonferroni may be overly conservative for exploratory analyses.
   Consider False Discovery Rate (FDR) as alternative.

4. **Focus on Effect Sizes:**
   Even if p>α_bonf, meaningful effect sizes (β) should be reported.

5. **Report What Survives:**
   Clearly state: "After Bonferroni correction for 149 tests,
   [X] effects remained significant at α=0.000336."

================================================================================
LIMITATIONS OF BONFERRONI
================================================================================

1. **Overly Conservative:**
   Assumes all tests are independent, which inflates false negatives.

2. **Not Ideal for Exploratory Work:**
   Bonferroni is best for pre-registered confirmatory hypotheses, not
   data-driven exploration.

3. **Alternatives Exist:**
   - Holm-Bonferroni (sequential, less conservative)
   - False Discovery Rate (FDR, controls proportion of false positives)
   - Permutation tests (data-driven, no distributional assumptions)

4. **Bayesian Paradigm Exempt:**
   Framework 4 uses Bayesian inference, which sidesteps FWER entirely.

================================================================================
FINAL VERDICT
================================================================================

✓ Bonferroni correction applied to Framework 1 results
✗ Most p<0.05 effects become non-significant (expected with n=149)
✓ This increases rigor but reduces sensitivity
→ Recommend reporting both corrected and uncorrected results with caveats

Conclusion: The conservative Bonferroni threshold (0.000336) is
appropriate for confirmatory claims but may obscure real effects in this
exploratory multi-framework analysis. Consider complementing with:
  - Effect size emphasis (β, 95% CI)
  - False Discovery Rate (FDR) control
  - Bayesian approaches (Framework 4, which avoids p-values)

================================================================================
END OF GUIDE
================================================================================
